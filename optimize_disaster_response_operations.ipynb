{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garylau1/model_training/blob/main/optimize_disaster_response_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91d88de",
      "metadata": {
        "id": "f91d88de"
      },
      "source": [
        "#### COMP3410/COMP6410 Knowledge, Planning and Decision Making under Uncertainty (2024 S2)\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ccacecb",
      "metadata": {
        "id": "0ccacecb"
      },
      "source": [
        "\n",
        "As part of this project, you will develop solutions to optimize disaster response operations using the techniques covered in the lecture series. Your task is to implement and test algorithms for path planning, decision-making, and multi-agent coordination in a simulated rescue scenario. Additionally, you will need to propose a project title that summarizes your designed solution, which will be a small part of the assignment as well.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Natural disasters often require quick and efficient rescue operations to minimize casualties and damage. In this assignment, you will use the concepts from **Adversarial Games and Multi-Agent Systems (Weeks 7-9)** and **Uncertainty in AI (Weeks 10-11)** to create solutions for a disaster response simulation.\n",
        "\n",
        "You will focus on applying genetic algorithms, ant colony optimization, the Minmax algorithm with alpha-beta pruning and its enhancements, multi-agent systems, game theory, and Bayesian networks. These methods will help you simulate decision-making in multi-agent rescue operations. While your solution should be grounded in the lecture material, you are encouraged to explore improvements for computational efficiency including your own design of advanced modifications to enhance performance and effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9220620f",
      "metadata": {
        "id": "9220620f"
      },
      "source": [
        "## Simulation Scenario\n",
        "\n",
        "An earthquake has struck NovaCity, causing widespread destruction, including fires, and road blockages. Emergency response teams need to be coordinated for rescue operations.\n",
        "\n",
        "The city is divided into **5 regions (R1 to R5)**. Each region has an evaluated **damage level** according to its blocked roads and fires:\n",
        "- High damage (H): $>=50\\%$ roads blocked, or $>=30\\%$ fires;\n",
        "- Medium damage (M): $[10\\%, 50\\%)$ roads blocked, or $[10\\%, 30\\%)$ fires; and\n",
        "- Low damage (L): $<10\\%$ roads blocked, or $<10\\%$ fires.\n",
        "\n",
        "Either blocked roads or fires that reach the range can be considered its damage level. For example, a region with 30\\% road blocks and 5\\% fires is Medium damaged.\n",
        "\n",
        "The **initial damage** to each region is provided:\n",
        "- R1 (H): 60\\% roads blocked, 35\\% fires;\n",
        "- R2 (M): 40\\% roads blocked, 25\\% fires;\n",
        "- R3 (M): 15\\% roads blocked, 5\\% fires;\n",
        "- R4 (H): 35\\% roads blocked, 30\\% fires; and\n",
        "- R5 (L): 5\\% roads blocked, 3\\% fires.\n",
        "\n",
        "Assume all regions are of equal size to simplify the modelling process. Each region is modelled as a **node** in a graph, and predefined **distances** between regions (e.g., 5 km between R1 and R2, 3 km between R2 and R3) are detailed: R1 -- R2: 5 km, R1 -- R3: 7 km, R1 -- R4: 4 km, R1 -- R5: 6 km, R2 -- R3: 3 km, R2 -- R4: 4 km, R2 -- R5: 8 km, R3 -- R4: 5 km, R3 -- R5: 6 km, and R4 -- R5: 4 km.\n",
        "\n",
        "During the rescue, each region will continue to experience fire spread and aftershocks. Fires spread every 10 minutes within the same region, increasing the fire percentage by 10\\%. Aftershocks occur randomly every 15 minutes increasing road blockages by 10\\% over all regions. For example, in R1, the initial damage is 60\\% roads blocked and 35\\% fires. After 10 minutes, it becomes $(60\\%, 45\\%)$, and after an additional 5 minutes, it becomes $(70\\%, 45\\%)$ if no rescue operations are performed.\n",
        "\n",
        "Rescue agents are distributed across regions at the start of the simulation. **Eight units of fire trucks start at R2.** Each fire truck unit decreases fire percentage by 10\\% per rescue operation. **Six units of police start at R4.** Each police unit decreases road blockages by 10\\% per rescue operation. Multiple agents/units can perform rescue operations at the same time in the same region. The effects of their actions are cumulative. For example, if 2 fire trucks are deployed to R1 simultaneously, the fire percentage decreases by 20\\% in one operation. Rescue operations affect the regional damage directly. If a fire truck reduces fire percentage by 10\\%, that 10\\% decrease is applied to the overall fire damage in that region, e.g., $20\\%-10\\%=10\\%$.\n",
        "\n",
        "**Assumption:** Both rescue operations and disaster events (fire spread and aftershocks) do not consume time in this simulation, but each unit can only perform rescue once when visiting the region. Rescue agents will not lose resources along a path, and all operations will occur instantly for the purpose of modelling. However, the effects of disasters and rescues will still be cumulative over time. Rescue agents aim to follow a path that covers all regions, ensuring each region is visited only once. After completing their assigned rescue tasks along the path, they must return to their starting point for a refill.\n",
        "\n",
        "**Travel Speed:** Rescue agents can travel at a maximum speed of 60 km/h on unblocked roads. If roads are blocked, their speed will be reduced according to the percentage of blocked roads in the region they are traveling to or from. The travel speed between two regions is determined by the average percentage of blocked roads in both regions. For example, if R1 has 60\\% blocked roads and R2 has 40\\% blocked roads, the average blocked road percentage is $(60\\% + 40\\%) / 2 = 50\\%$. The travel speed will then be reduced by 50\\%, resulting in a travel speed of 30 km/h. Rescue agents won’t block each other. Fire damage will not affect travel speed.\n",
        "\n",
        "Rescue operations must be completed within 90 minutes and the sooner the better. You need to allocate resources efficiently, prioritize critical regions, and adapt to changing conditions like fire spread and aftershocks. Rescue agents must quickly respond to new blockages and worsening fires, adjusting strategies to minimize delays."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48cf2111",
      "metadata": {
        "id": "48cf2111"
      },
      "source": [
        "## Task Breakdown and their Objectives\n",
        "\n",
        "1. **Genetic Algorithms for Path Optimization**: Implement a genetic algorithm to design and develop efficient pathfinding algorithms that help rescue agents navigate disaster environments quickly and effectively. The implementation should use multiple successors to improve path selection and minimize overall rescue time.\n",
        "\n",
        "2. **Ant Colony Optimization (ACO) for Multi-Agent Coordination**:  Simulate how each rescue unit (e.g., polices and fire trucks) employs ACO to coordinate their movements to find their optimal paths. Assume agents can communicate in real time to share updated road and fire conditions once they arrive at the scene. The simulation should dynamically update “pheromone levels” as new road blockages or fires occur, improving the collaboration of multi-agent systems to ensure optimal use of resources and timely responses in disaster scenarios.\n",
        "\n",
        "3. **Minmax Algorithm with Alpha-Beta Pruning and Enhancements**: Implement the Minmax algorithm with Alpha-Beta Pruning to improve decision-making in competitive rescue scenarios, e.g., rescue agent vs fire spread/aftershock. Additionally, explore further computational enhancements, such as negamax or other advanced modifications of your design, to optimize the evaluation of rescue strategies, e.g, the number of units should be assigned to the same location, and improve decision-making efficiency.\n",
        "\n",
        "4. **Game Theory for Multi-Agent Systems**: Model an uncertain strategy by assigning predefined parameters specific values using game theory. Identify an appropriate equilibrium (such as Nash equilibrium, dominant strategy equilibrium, or another relevant concept) to maximize overall success.\n",
        "\n",
        "5. **Bayesian Networks for Uncertain Inferences**: Develop Bayesian networks to handle uncertainties in rescue operations, such as fire spread or road blockages. Use Conditional Probability Tables (CPTs) to model incomplete information and support agents in making better-informed decisions under evolving conditions.\n",
        "\n",
        "The objectives may not be developed in sequence. As you work through the assignment, keep the overall design of the solution in mind and carefully consider where each method or solution best fits to achieve the overall project goals."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba642903",
      "metadata": {
        "id": "ba642903"
      },
      "source": [
        "## Assignment Requirements\n",
        "\n",
        "1. **Overall Project Title and Design**: Begin by naming your project and reporting your overall project design. Describe how you plan to approach the disaster response simulation as a whole.\n",
        "\n",
        "2. **Linking Tasks to the Design**: Clearly explain how each task (genetic algorithms, ACO, Minmax, game theory, Bayesian networks) fits into your overall design. Show how these tasks are expected to contribute to solving the problem.\n",
        "\n",
        "3. **Task-Specific Design**: For each task, provide detailed explanations of your approach, including any required calculations, step-by-step explanations, and referenced equations. Your written design should clearly describe how you will tackle each specific task.\n",
        "\n",
        "4. **Code Development**: Provide the corresponding code that fully implements both your task-specific design and the overall project design. You don’t need to repeat the same code in multiple sections, but you must reference and explain the code clearly in your design reporting. This ensures that your written report ties directly into your coding implementation, showing how the code achieves the project goals and the performance of each individual task.\n",
        "\n",
        "5. **Submission**: The final submission should be in the Jupyter Notebook format (.ipynb) that you downloaded. Once completed, submit this notebook as your final submission. Initial contents like instructions can be removed in your final submission. Use Markdown cells to write your design report, including explanations, calculations, and step-by-step approaches. The code for each task should be placed in the corresponding code cells, ensuring it’s well-integrated with the report. Organize your notebook clearly using appropriate heading structures. Use: # for Level 1 (main headings), ## for Level 2 (subheadings), ### for Level 3 (sub-subheadings), etc. Ensure that all code in the notebook is fully executable. Each section’s code should output relevant results that support the design made in the report. The notebook should be easy to navigate. Use comments within your code to explain key parts of the implementation where necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3abe391d",
      "metadata": {
        "id": "3abe391d"
      },
      "source": [
        "## Marking Guidelines\n",
        "\n",
        "- **Overall design (10 marks)**: Clear and well-structured overall project design. Proper linkage of tasks to the overall solution. Thoughtful consideration of how each method fits into the project’s goals.\n",
        "\n",
        "- **Breakdown Tasks**: Clear explanation of the design and approaches in the report and correct implementation by coding.\n",
        "    - Task 1: Genetic Algorithms (15 marks)\n",
        "    - Task 2: ACO (15 marks)\n",
        "    - Task 3: Minmax Algorithm (20 marks)\n",
        "    - Task 4: Game Theory (15 marks)\n",
        "    - Task 5: Bayesian Networks (15 marks).\n",
        "\n",
        "- **Clarity and Style for Report and Code (10 marks)**: Clear, well-structured report that explains the design and tasks effectively. Proper organization using headings and step-by-step explanations. Well-commented and easy-to-read code. Code runs correctly and produces the expected results for each task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35bfdcf8",
      "metadata": {
        "id": "35bfdcf8"
      },
      "source": [
        "## Special Consideration and Late Submissions\n",
        "\n",
        "Unless a Special Consideration request has been submitted and approved, a **5% penalty** (ofthe total possible mark) will be applied each day a written assessment is not submitted, upuntil the 7th day (including weekends). After the 7th day, a grade of '0' will be awarded evenif the assessment is submitted. Submission time for all written assessments is set at **11:55pm**. A 1-hour grace period is provided to students who experience a technical concern.\n",
        "\n",
        "For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, students need to submit an application for Special Consideration.\n",
        "\n",
        "- Assignment 1: YES, Standard Late Penalty applies\n",
        "- **Assignment 2: YES, Standard Late Penalty applies**\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61fe965",
      "metadata": {
        "id": "e61fe965"
      },
      "source": [
        "_Below is the start of your Assignment 2. Edition over provided structure is allowed. Instructions and hints can be removed in your final submission._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f353075",
      "metadata": {
        "id": "0f353075"
      },
      "source": [
        "# Project Title:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf1d036",
      "metadata": {
        "id": "8cf1d036"
      },
      "source": [
        "_Author details_\n",
        "\n",
        "- Student Name: Gary Tze hay Lau\n",
        "- ID Number: 45245673\n",
        "- Email Address: gary.tzehay.lau@gmail.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb497f8",
      "metadata": {
        "id": "cdb497f8"
      },
      "source": [
        "# Overall Design and Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fffb734",
      "metadata": {
        "id": "3fffb734"
      },
      "source": [
        "\n",
        "\n",
        "### Project Title: Optimized Disaster Response Simulation for NovaCity\n",
        "\n",
        "The project, \"Optimized Disaster Response Simulation for NovaCity,\" aims to create an integrated, multi-algorithmic approach to disaster management in an earthquake-affected urban environment. The simulation combines various optimization and analytical techniques to efficiently allocate resources and coordinate rescue efforts in the aftermath of the earthquake that struck NovaCity. The objective is to minimize damage, improve response times, and ensure comprehensive rescue operations under uncertain and dynamic conditions.\n",
        "\n",
        "The approach includes five key tasks, each contributing to the overall disaster response strategy. Task 1 involves using Genetic Algorithms (GA) to determine optimal paths for rescue agents, such as fire trucks and police units, aiming to minimize travel time and efficiently address fire and road blockage incidents. Task 2 builds upon these paths by employing Ant Colony Optimization (ACO) to further improve rescue agent movement by considering dynamic changes in fire spread and road blockages.\n",
        "\n",
        "In Task 3, the Minimax algorithm with Alpha-Beta Pruning is utilized to allocate rescue units efficiently across regions, ensuring critical areas receive priority. This allocation is then analyzed in Task 4 through the lens of Game Theory, which identifies Nash Equilibria, Dominant Strategies, and Weak Dominant Strategies for optimal resource distribution. Finally, Task 5 incorporates Bayesian Networks to handle uncertainties related to fire spread and aftershocks, allowing for informed decision-making and adaptability in resource allocation.\n",
        "\n",
        "By integrating GA, ACO, Minimax, Game Theory, and Bayesian Networks, this project provides a comprehensive framework for optimizing rescue operations in NovaCity. It demonstrates how the combination of diverse optimization techniques and probabilistic reasoning can effectively address the complexities of disaster response, enabling efficient and adaptive rescue strategies in a highly uncertain environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e794db",
      "metadata": {
        "id": "61e794db"
      },
      "source": [
        "# Breakdown Tasks\n",
        "\n",
        "You should reorder Tasks 1-5 following the steps in your overall design."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84bcfc23",
      "metadata": {
        "id": "84bcfc23"
      },
      "source": [
        "## Task 1: Genetic Algorithms for Path Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9361f2",
      "metadata": {
        "id": "af9361f2"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ The successor of exchange might fit more to this project than mutation. Successor works on `path[1:]` as the start location is fixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "crUXUAv4QrWS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crUXUAv4QrWS",
        "outputId": "2a7628f6-c5d9-4fa7-efdb-7d732b8eb452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c7e9736",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c7e9736",
        "outputId": "34b1e890-5c6f-4ead-c092-dc01c155cb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "# Task 1: Path Optimization for Rescue Operations\n",
        "\n",
        "# The goal:\n",
        "# Use a genetic algorithm to determine the best paths for fire trucks and police units to minimize rescue time and efficiently handle fire and road blockage incidents.\n",
        "\n",
        "# Input:\n",
        "# - The initial state of the city (fire levels, road blockages).\n",
        "# - Genetic algorithm parameters like crossover and mutation probability, generations, and population size.\n",
        "\n",
        "# Output:\n",
        "# - The optimal paths for fire trucks and police units.\n",
        "\n",
        "# Next Step:\n",
        "# Utilize the optimized paths from this genetic algorithm solution in Task 2 to determine efficient allocation and sequencing of rescue units.\n",
        "\n",
        "\n",
        "# Define constants for the regions and initial damage levels using indices\n",
        "REGION_MAP = {'R1': 0, 'R2': 1, 'R3': 2, 'R4': 3, 'R5': 4}  # Mapping of regions to indices\n",
        "\n",
        "REVERSE_REGION_MAP = {v: k for k, v in REGION_MAP.items()}  # To convert indices back to region names\n",
        "DISTANCES = {\n",
        "    (0, 1): 5, (0, 2): 7, (0, 3): 4, (0, 4): 6,\n",
        "    (1, 2): 3, (1, 3): 4, (1, 4): 8,\n",
        "    (2, 3): 5, (2, 4): 6, (3, 4): 4\n",
        "}  # Distances between regions\n",
        "START_LOCATIONS = {'fire_truck': 1, 'police_truck': 3}  # Start locations as indices for R2 and R4\n",
        "MAX_TIME = 90  # Maximum allowed time in minutes\n",
        "\n",
        "# Set up DEAP framework to create individuals for our genetic algorithm\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # Minimize fitness\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMin)  # Define an individual as a list with a fitness attribute\n",
        "\n",
        "toolbox = base.Toolbox()  # Create a toolbox to contain evolutionary operators\n",
        "toolbox.register(\"indices\", random.sample, list(REGION_MAP.values()), len(REGION_MAP))  # Generates a random path\n",
        "toolbox.register(\"individual\", tools.initIterate, creator.Individual, lambda: toolbox.indices()[1:])  # Exclude starting region\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)  # Create population\n",
        "\n",
        "def fitness_function(individual, start_region):\n",
        "    \"\"\"\n",
        "    Calculate the fitness of an individual path for a given rescue team.\n",
        "\n",
        "    Parameters:\n",
        "    individual (list): The sequence of regions to visit.\n",
        "    start_region (int): The index of the starting region.\n",
        "\n",
        "    Returns:\n",
        "    tuple: The fitness score of the individual.\n",
        "    \"\"\"\n",
        "    total_time = 0  # Initialize total travel time\n",
        "    current_region = start_region  # Start from the initial region for the specific rescue team\n",
        "    fire_levels = {0: 35, 1: 25, 2: 5, 3: 30, 4: 3}  # Initial fire levels in each region by index\n",
        "    road_blockages = {0: 60, 1: 40, 2: 15, 3: 35, 4: 5}  # Initial blockage percentages in each region by index\n",
        "    time_counter = 0  # Tracks cumulative time as the agent progresses along the path\n",
        "    total_penalty = 0  # Track the total penalty based on worsening conditions\n",
        "\n",
        "    # Loop through each region in the individual path, including a return to start at the end\n",
        "    for next_region in individual + [start_region]:\n",
        "        # Get the distance between the current and next region\n",
        "        distance = DISTANCES.get((current_region, next_region), DISTANCES.get((next_region, current_region), None))\n",
        "        if distance is None:\n",
        "            continue  # Skip if no direct path is available\n",
        "\n",
        "        # Calculate average blockage to determine travel speed\n",
        "        avg_blockage = (road_blockages[current_region] + road_blockages[next_region]) / 2\n",
        "        speed = max(1, 60 * (1 - avg_blockage / 100))  # Adjust speed based on blockage percentage\n",
        "        travel_time = distance / (speed / 60)  # Calculate travel time in minutes\n",
        "\n",
        "        # Accumulate total time and time counter\n",
        "        total_time += travel_time\n",
        "        time_counter += travel_time\n",
        "\n",
        "        # Fire spread effect: Increment fire level by 10% every 10 minutes\n",
        "        fire_spread_events = int(time_counter // 10)  # Number of 10-minute intervals passed\n",
        "        for region in fire_levels:\n",
        "            fire_levels[region] = min(100, fire_levels[region] + fire_spread_events * 10)  # Cap at 100%\n",
        "\n",
        "        # Aftershock effect: Increase road blockage by 10% every 15 minutes across all regions\n",
        "        aftershock_events = int(time_counter // 15)  # Number of 15-minute intervals passed\n",
        "        for region in road_blockages:\n",
        "            road_blockages[region] = min(100, road_blockages[region] + aftershock_events * 10)  # Cap at 100%\n",
        "\n",
        "        # Apply rescue effects based on the type of rescue agent, once per region visit\n",
        "        if next_region != start_region:  # Avoid applying rescue on return trip to start\n",
        "            if start_region == START_LOCATIONS['fire_truck']:  # Fire trucks start at R2\n",
        "                fire_reduction = min(100, 10 * 8)  # 8 trucks reduce fire by 10% each, cumulative effect of 80%\n",
        "                fire_levels[next_region] = max(0, fire_levels[next_region] - fire_reduction)  # Apply cumulative fire reduction\n",
        "            elif start_region == START_LOCATIONS['police_truck']:  # Police units start at R4\n",
        "                blockage_reduction = min(100, 10 * 6)  # 6 police units reduce blockage by 10% each, cumulative effect of 60%\n",
        "                road_blockages[next_region] = max(0, road_blockages[next_region] - blockage_reduction)  # Apply cumulative blockage reduction\n",
        "\n",
        "        # Apply damage level penalty based on fire and blockage levels when the region is visited\n",
        "        if fire_levels[next_region] >= 30 or road_blockages[next_region] >= 50:\n",
        "            # High Damage penalty factor\n",
        "            total_penalty += 15  # Increase penalty for high-damage regions to prioritize them\n",
        "        elif 10 <= fire_levels[next_region] < 30 or 10 <= road_blockages[next_region] < 50:\n",
        "            # Medium Damage penalty factor\n",
        "            total_penalty += 5  # Moderate penalty for medium-damage regions\n",
        "\n",
        "        # Move to the next region in the path\n",
        "        current_region = next_region\n",
        "\n",
        "    # Gradual penalty if total time exceeds the maximum allowed time\n",
        "    if total_time > MAX_TIME:\n",
        "        total_penalty += (total_time - MAX_TIME) * 1.5  # Apply a more moderate penalty for exceeding the time limit\n",
        "\n",
        "    # Combine total time and total penalty for the final fitness score\n",
        "    fitness_score = total_time + total_penalty\n",
        "    return fitness_score,\n",
        "\n",
        "# Register the fitness function with the toolbox\n",
        "toolbox.register(\"evaluate\", fitness_function, start_region=START_LOCATIONS['fire_truck'])  # Register fitness function for fire truck\n",
        "toolbox.register(\"mate\", tools.cxPartialyMatched)  # Crossover function for genetic algorithm\n",
        "toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.4)  # Increased mutation probability\n",
        "toolbox.register(\"select\", tools.selRoulette)  # Using roulette selection for broader exploration\n",
        "\n",
        "# Generate the initial population\n",
        "def generate_initial_population(start_location, population_size=100):\n",
        "    \"\"\"\n",
        "    Generate the initial population for the genetic algorithm.\n",
        "\n",
        "    Parameters:\n",
        "    start_location (int): The starting region for the population.\n",
        "    population_size (int): The size of the population.\n",
        "\n",
        "    Returns:\n",
        "    list: The initial population of individuals.\n",
        "    \"\"\"\n",
        "    toolbox.register(\"evaluate\", fitness_function, start_region=start_location)  # Register the function based on start location\n",
        "    population = [creator.Individual(list(toolbox.indices())) for _ in range(population_size)]  # Generate initial paths\n",
        "    return population\n",
        "\n",
        "# Exchange function for mutation - Swaps two regions in the path\n",
        "def exchange(individual):\n",
        "    \"\"\"\n",
        "    Exchange mutation function: Swaps two random regions in the individual's path.\n",
        "\n",
        "    Parameters:\n",
        "    individual (list): The individual's path.\n",
        "\n",
        "    Returns:\n",
        "    tuple: The mutated individual.\n",
        "    \"\"\"\n",
        "    i, j = random.sample(range(len(individual)), 2)  # Select two random positions to swap\n",
        "    individual[i], individual[j] = individual[j], individual[i]  # Perform the swap\n",
        "    return individual,\n",
        "\n",
        "toolbox.register(\"exchange\", exchange)  # Register exchange as a mutation option\n",
        "toolbox.register(\"successor\", exchange)  # Set successor to be exchange-based for this task\n",
        "\n",
        "# Main function to run the genetic algorithm\n",
        "def genetic_algorithm(population, generations=200):\n",
        "    \"\"\"\n",
        "    Run the genetic algorithm to find the optimal path.\n",
        "\n",
        "    Parameters:\n",
        "    population (list): The initial population of individuals.\n",
        "    generations (int): The number of generations to evolve.\n",
        "\n",
        "    Returns:\n",
        "    list: The top 10 unique best paths found by the genetic algorithm.\n",
        "    \"\"\"\n",
        "    best_paths = []  # List to store the best paths found\n",
        "    for gen in range(generations):\n",
        "        offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.4)  # Increased mutation probability\n",
        "        fits = map(toolbox.evaluate, offspring)  # Evaluate fitness of each individual\n",
        "        for fit, ind in zip(fits, offspring):\n",
        "            ind.fitness.values = fit  # Assign fitness values\n",
        "\n",
        "        population = toolbox.select(offspring, k=len(population))  # Select the next generation\n",
        "\n",
        "        # Store the top 10 paths in each generation\n",
        "        top_10 = tools.selBest(population, k=10)\n",
        "        best_paths.extend([(tuple(ind), ind.fitness.values[0]) for ind in top_10])\n",
        "\n",
        "    # Return only the unique best paths by converting individuals to tuples\n",
        "    unique_best_paths = list(dict.fromkeys(best_paths))  # Remove duplicate paths by using tuples as dictionary keys\n",
        "    return sorted(unique_best_paths, key=lambda x: x[1])[:10]  # Return the top 10 unique best paths\n",
        "\n",
        "# Run the algorithm for both fire trucks and police units\n",
        "fire_truck_population = generate_initial_population(START_LOCATIONS['fire_truck'])\n",
        "police_truck_population = generate_initial_population(START_LOCATIONS['police_truck'])\n",
        "\n",
        "fire_truck_best_paths = genetic_algorithm(fire_truck_population)\n",
        "police_truck_best_paths = genetic_algorithm(police_truck_population)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7383378",
      "metadata": {
        "id": "d7383378"
      },
      "source": [
        "## Task 2: Ant Colony Optimization (ACO) for Multi-Agent Coordination"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6df3a9",
      "metadata": {
        "id": "4b6df3a9"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ Fire trucks and polices need to be handled seperately when implementing ACO.\n",
        "\n",
        "Similar to the calculation of the averaged blockages between two regions, the pheromone level can be determined by averaging the conditions of the two connected regions. For example, $\\rho^{\\text{fire}}_{R_1R_2} = 1 - [\\text{fire damage}(R1)+\\text{fire damage}(R2)]/2/100$.\n",
        "\n",
        "Additionally, the equations are provided for your convenience in reporting.\n",
        "\n",
        "$$\\tau_{ij} \\leftarrow \\text{Evaporation}(\\tau_{ij})$$\n",
        "\n",
        "$$\\tau_{ij} \\leftarrow \\text{Rescue}(\\tau_{ij})$$ where `Evaporation` can be fire spread or aftershock, `Rescue` can be from a unit of fire truck or a unit of police.\n",
        "\n",
        "$$\\eta_{ij}=1/d_{ij}$$\n",
        "\n",
        "$$p^k_{ij}=\\frac{[\\tau_{ij}]^\\alpha[\\eta_{ij}]^\\beta}{\\sum_{l\\in N_k(i)}[\\tau_{il}]^\\alpha[\\eta_{il}]^\\beta}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e0b0d2",
      "metadata": {
        "id": "37e0b0d2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Goal:\n",
        "# Use Ant Colony Optimization (ACO) to simulate efficient agent movement through the regions while considering dynamic conditions such as worsening fires and road blockages.\n",
        "\n",
        "# Input:\n",
        "# - Pheromone and heuristic information for each edge between regions.\n",
        "# - Fire and road blockage levels for each region.\n",
        "# - Best paths generated from Task 1.\n",
        "\n",
        "# Output:\n",
        "# - Total travel time for fire trucks and police units following the paths.\n",
        "# - Updated fire and bloackage levels.\n",
        "\n",
        "# Next Step:\n",
        "# Utilize the updated fire and road blockage levels in Task 3 to determine appropriate resource allocation strategies considering the worsening conditions in NovaCity.\n",
        "\n",
        "# Linked to Task 1:\n",
        "# - The best paths obtained from Task 1 (`fire_truck_best_paths` and `police_truck_best_paths`) are used to simulate agent movement in Task 2.\n",
        "\n",
        "# Initialize parameters for ACO\n",
        "alpha = 1  # Influence of pheromone\n",
        "beta = 2   # Influence of heuristic information (distance)\n",
        "evaporation_rate = 0.5  # Rate at which pheromone evaporates per time step\n",
        "\n",
        "# Initialize pheromone and heuristic values for each edge between regions\n",
        "pheromones = {(i, j): 1.0 for i in REGION_MAP.values() for j in REGION_MAP.values() if i != j}\n",
        "heuristics = {(i, j): 1 / DISTANCES[(i, j)] if (i, j) in DISTANCES else 1 / DISTANCES[(j, i)] for i, j in pheromones}\n",
        "\n",
        "# Function to evaporate pheromones due to worsening conditions\n",
        "def evaporate_pheromones(pheromones, fire_levels, road_blockages):\n",
        "    \"\"\"\n",
        "    Evaporate pheromones on each edge based on the current average fire and blockage levels.\n",
        "\n",
        "    Parameters:\n",
        "    pheromones (dict): Pheromone levels for each edge.\n",
        "    fire_levels (dict): Fire levels for each region.\n",
        "    road_blockages (dict): Road blockage levels for each region.\n",
        "\n",
        "    Returns:\n",
        "    None: Pheromone values are updated directly.\n",
        "    \"\"\"\n",
        "    for (i, j) in pheromones:\n",
        "        fire_avg = (fire_levels[i] + fire_levels[j]) / 2  # Calculate average fire level between regions\n",
        "        blockage_avg = (road_blockages[i] + road_blockages[j]) / 2  # Calculate average road blockage level\n",
        "        pheromones[(i, j)] *= (1 - evaporation_rate * (fire_avg + blockage_avg) / 100)  # Evaporate pheromones\n",
        "\n",
        "# Function to deposit pheromones after rescue operations\n",
        "def deposit_pheromones(pheromones, path, increase_factor=1.0):\n",
        "    \"\"\"\n",
        "    Deposit pheromones along the path to indicate successful rescue operations.\n",
        "\n",
        "    Parameters:\n",
        "    pheromones (dict): Pheromone levels for each edge.\n",
        "    path (list): List of regions in the path.\n",
        "    increase_factor (float): Amount of pheromone to deposit for each edge.\n",
        "\n",
        "    Returns:\n",
        "    None: Pheromone values are updated directly.\n",
        "    \"\"\"\n",
        "    for i in range(len(path) - 1):\n",
        "        edge = (path[i], path[i + 1])\n",
        "        pheromones[edge] += increase_factor  # Increase pheromone value for each edge in the path\n",
        "\n",
        "# Function to choose the next region based on pheromone levels and heuristics\n",
        "def choose_next_region(current_region, pheromones, heuristics, visited):\n",
        "    \"\"\"\n",
        "    Choose the next region for the agent based on pheromone levels and heuristic information.\n",
        "\n",
        "    Parameters:\n",
        "    current_region (int): The current region of the agent.\n",
        "    pheromones (dict): Pheromone levels for each edge.\n",
        "    heuristics (dict): Heuristic values (distance) for each edge.\n",
        "    visited (set): Set of visited regions.\n",
        "\n",
        "    Returns:\n",
        "    int: The next region chosen for the agent to move to.\n",
        "    \"\"\"\n",
        "    probabilities = {}\n",
        "    for neighbor in REGION_MAP.values():\n",
        "        if neighbor != current_region and neighbor not in visited:\n",
        "            tau = pheromones[(current_region, neighbor)]  # Pheromone level\n",
        "            eta = heuristics[(current_region, neighbor)]  # Heuristic value\n",
        "            probabilities[neighbor] = (tau ** alpha) * (eta ** beta)  # Calculate probability for each neighbor\n",
        "    total = sum(probabilities.values())\n",
        "    if total == 0:\n",
        "        return None  # No valid moves available\n",
        "    probabilities = {k: v / total for k, v in probabilities.items()}  # Normalize probabilities\n",
        "    return random.choices(list(probabilities.keys()), weights=list(probabilities.values()))[0]  # Choose based on probability\n",
        "\n",
        "# Function to calculate travel time on an edge considering road blockage\n",
        "def edge_travel_time(i, j, road_blockages):\n",
        "    \"\"\"\n",
        "    Calculate the travel time between two regions considering the average road blockage.\n",
        "\n",
        "    Parameters:\n",
        "    i (int): Starting region.\n",
        "    j (int): Destination region.\n",
        "    road_blockages (dict): Road blockage levels for each region.\n",
        "\n",
        "    Returns:\n",
        "    float: The travel time in minutes.\n",
        "    \"\"\"\n",
        "    if i == j:\n",
        "        return 0  # No travel time if both regions are the same\n",
        "    avg_blockage = (road_blockages[i] + road_blockages[j]) / 2  # Average blockage level between regions\n",
        "    speed = max(1, 60 * (1 - avg_blockage / 100))  # Adjust speed based on blockage percentage\n",
        "    distance = DISTANCES[(i, j)] if (i, j) in DISTANCES else DISTANCES[(j, i)]\n",
        "    return distance / (speed / 60)  # Travel time in minutes\n",
        "\n",
        "# Function to simulate agent movement along a given path and update pheromones\n",
        "def simulate_agent_path(path, start_region, fire_levels, road_blockages, agent_type):\n",
        "    \"\"\"\n",
        "    Simulate agent movement along a path and update pheromones and conditions accordingly.\n",
        "\n",
        "    Parameters:\n",
        "    path (list): List of regions in the path.\n",
        "    start_region (int): The starting region of the agent.\n",
        "    fire_levels (dict): Fire levels for each region.\n",
        "    road_blockages (dict): Road blockage levels for each region.\n",
        "    agent_type (str): Type of agent ('fire_truck' or 'police_truck').\n",
        "\n",
        "    Returns:\n",
        "    float: Total time taken for the agent to complete the path.\n",
        "    \"\"\"\n",
        "    current_region = start_region\n",
        "    visited = {current_region}  # Track visited regions\n",
        "    total_time = 0  # Initialize total travel time\n",
        "\n",
        "    # Loop through the path and simulate the agent's movement\n",
        "    for next_region in path[1:]:\n",
        "        if current_region == next_region:\n",
        "            continue  # Skip if the next region is the same as the current one\n",
        "\n",
        "        # Calculate travel time and add it to total time\n",
        "        travel_time = edge_travel_time(current_region, next_region, road_blockages)\n",
        "        total_time += travel_time\n",
        "\n",
        "        # Update pheromones for worsening conditions (evaporation)\n",
        "        evaporate_pheromones(pheromones, fire_levels, road_blockages)\n",
        "\n",
        "        # Perform rescue operation: decrease fire or blockage, increase pheromone\n",
        "        if agent_type == 'fire_truck':\n",
        "            fire_levels[next_region] = max(0, fire_levels[next_region] - 10)  # Reduce fire by 10%\n",
        "            deposit_pheromones(pheromones, [current_region, next_region], increase_factor=0.1 * fire_levels[next_region])\n",
        "        elif agent_type == 'police_truck':\n",
        "            road_blockages[next_region] = max(0, road_blockages[next_region] - 10)  # Reduce blockage by 10%\n",
        "            deposit_pheromones(pheromones, [current_region, next_region], increase_factor=0.1 * road_blockages[next_region])\n",
        "\n",
        "        # Move to the next region\n",
        "        current_region = next_region\n",
        "        visited.add(current_region)\n",
        "\n",
        "    return total_time\n",
        "\n",
        "# Initial fire and blockage conditions for regions\n",
        "initial_fire_levels = {0: 35, 1: 25, 2: 5, 3: 30, 4: 3}\n",
        "initial_road_blockages = {0: 60, 1: 40, 2: 15, 3: 35, 4: 5}\n",
        "\n",
        "# Copy initial conditions for tracking the final states after the ACO simulation\n",
        "final_fire_levels = initial_fire_levels.copy()\n",
        "final_road_blockages = initial_road_blockages.copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ac383f",
      "metadata": {
        "id": "09ac383f"
      },
      "source": [
        "## Task 3: Minmax Algorithm with Alpha-Beta Pruning and Enhancements"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae23ae49",
      "metadata": {
        "id": "ae23ae49"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_\n",
        "\n",
        "Who is **Max Player**?\n",
        "\n",
        "Who is **Min Player**?\n",
        "\n",
        "**Game tree construction** Any data should be prepared by pre-computation? Utility?\n",
        "\n",
        "|            |       |     |      |         |      |\n",
        "| ---------- |  -----|-----|------|-------- | -----|\n",
        "|`path[0]`   |  Max  |     |      |  #units   |    |\n",
        "|            |       |     |      |     l     |    |\n",
        "|            | Min   |     |      |     fires |    |\n",
        "|            |       |   / |    / |       l   | \\  |\n",
        "|`path[1]`   | Max   |  #units  | #units-1| ...|  1   |\n",
        "|            |       |   l |  l   |            |     |\n",
        "|            | Min   |fires|fires |  ...   |         |\n",
        "|`path[2]`   | ...   |  ...|//...l...\\\\   |   ...   |       |\n",
        "|      ...   |       |     | #units-1 .... 1     |  ...    |     |\n",
        "|`path[4]`   |  ...  | ... |  ... |  ...    |  ... |\n",
        "\n",
        "Start with total number of units of agents at `path[0]`. For each region `path[i]`, the number units of agents assigned can be from the available units at that point down to one. Compute all possible allocations for the regions (`path[1]`, `path[2]`, `path[3]`, `path[4]`) based on the remaining units after allocation at the current region. Recursively list all possible combinations of allocations along the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f167e83",
      "metadata": {
        "id": "3f167e83"
      },
      "outputs": [],
      "source": [
        "# Ensure we have the best paths from Task 2\n",
        "best_fire_path = fire_truck_best_paths[0][0]  # Best path for fire trucks (from Task 2)\n",
        "best_police_path = police_truck_best_paths[0][0]  # Best path for police trucks (from Task 2)\n",
        "\n",
        "# Goal:\n",
        "# Use the Minimax algorithm with Alpha-Beta pruning to allocate rescue units efficiently while considering worsening conditions.\n",
        "# This will help optimize rescue operations and ensure critical regions receive sufficient resources.\n",
        "\n",
        "# Input:\n",
        "# - Final fire levels and road blockage levels from Task 2.\n",
        "# - The best paths for fire trucks and police trucks from Task 2.\n",
        "# - Constants for maximum fire and police units.\n",
        "\n",
        "# Output:\n",
        "# - Best allocation paths for fire and police units.\n",
        "# - Best utility value representing optimal rescue efficiency.\n",
        "\n",
        "# Next Step:\n",
        "# Integrate this solution with Task 4 (Game Theory for Multi-Agent Systems) to analyze equilibrium in the resource allocation.\n",
        "\n",
        "# Constants for Task 3\n",
        "MAX_FIRE_UNITS = 8  # Maximum number of fire truck units available\n",
        "MAX_POLICE_UNITS = 6  # Maximum number of police units available\n",
        "MAX_DEPTH = 5  # Maximum depth for Minimax algorithm tree\n",
        "region_names={0: 'R1', 1: 'R2', 2: 'R3', 3: 'R4', 4: 'R5'} # the region names\n",
        "# Define utility function prioritizing critical regions (R1, R2, R4)\n",
        "def calculate_utility(fire_levels, road_blockages, path):\n",
        "    \"\"\"\n",
        "    Calculate the utility value based on the state of fire levels and road blockages.\n",
        "\n",
        "    Parameters:\n",
        "    fire_levels (dict): Dictionary containing the fire levels for each region.\n",
        "    road_blockages (dict): Dictionary containing the road blockage levels for each region.\n",
        "    path (list): List representing the path to be evaluated.\n",
        "\n",
        "    Returns:\n",
        "    int: Utility value for the given path.\n",
        "    \"\"\"\n",
        "    utility = 0  # Initialize utility value to 0\n",
        "    for region in path:  # Loop through each region in the path\n",
        "        # Assign higher priority for regions R1, R2, and R4 (0, 1, 3)\n",
        "        priority_factor = 9 if region in [0, 1, 3] else 3  # Assign priority factor based on region\n",
        "\n",
        "        # Calculate utility value by considering the reduction in fire and road blockages\n",
        "        utility += priority_factor * ((100 - fire_levels[region]) + (100 - road_blockages[region]))\n",
        "\n",
        "    return utility  # Return the calculated utility value\n",
        "\n",
        "# Minimax function with Alpha-Beta pruning to allocate rescue resources\n",
        "def minimax_with_alpha_beta(fire_levels, road_blockages, path, depth, remaining_fire_units, remaining_police_units, is_max_turn, alpha, beta, fire_allocation_path, police_allocation_path):\n",
        "    \"\"\"\n",
        "    Minimax algorithm with Alpha-Beta pruning to allocate fire and police units effectively.\n",
        "\n",
        "    Parameters:\n",
        "    fire_levels (dict): Fire levels in each region.\n",
        "    road_blockages (dict): Road blockage levels in each region.\n",
        "    path (list): List of regions in the current path.\n",
        "    depth (int): Current depth in the Minimax tree.\n",
        "    remaining_fire_units (int): Number of remaining fire units available.\n",
        "    remaining_police_units (int): Number of remaining police units available.\n",
        "    is_max_turn (bool): Flag indicating if it's a maximizing player's turn.\n",
        "    alpha (float): Alpha value for pruning.\n",
        "    beta (float): Beta value for pruning.\n",
        "    fire_allocation_path (list): Allocation path for fire units.\n",
        "    police_allocation_path (list): Allocation path for police units.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Best utility value, allocation paths for fire and police units.\n",
        "    \"\"\"\n",
        "    # Base case: If depth limit reached or no units left\n",
        "    if depth == MAX_DEPTH or (remaining_fire_units == 0 and remaining_police_units == 0):\n",
        "        # Calculate utility for current state\n",
        "        return calculate_utility(fire_levels, road_blockages, path), fire_allocation_path, police_allocation_path\n",
        "\n",
        "    # Maximizing player's turn (Allocate fire and police units to minimize damage)\n",
        "    if is_max_turn:\n",
        "        max_eval = float('-inf')  # Initialize maximum evaluation value to negative infinity\n",
        "        best_fire_allocation_path = None  # Best allocation path for fire units\n",
        "        best_police_allocation_path = None  # Best allocation path for police units\n",
        "\n",
        "        # Iterate over possible allocations for fire and police units\n",
        "        for fire_alloc in range(1, min(remaining_fire_units + 1, MAX_FIRE_UNITS + 1)):\n",
        "            for police_alloc in range(1, min(remaining_police_units + 1, MAX_POLICE_UNITS + 1)):\n",
        "                region = path[depth]  # Get current region from the path\n",
        "\n",
        "                # If it's the first depth level and region is one of the priority regions (R1, R2, R4), ensure minimum allocation of 2 units\n",
        "                if region in [0, 1, 3] and depth == 0:\n",
        "                    fire_alloc = max(2, fire_alloc)  # Allocate at least 2 fire units\n",
        "                    police_alloc = max(2, police_alloc)  # Allocate at least 2 police units\n",
        "\n",
        "                # Apply fire and police allocations to the current region\n",
        "                fire_levels[region] = max(0, fire_levels[region] - 10 * fire_alloc)  # Reduce fire levels by allocated fire units\n",
        "                road_blockages[region] = max(0, road_blockages[region] - 10 * police_alloc)  # Reduce road blockages by allocated police units\n",
        "\n",
        "                # Recursively call Minimax for the next depth (Min player's turn)\n",
        "                eval_value, new_fire_allocation_path, new_police_allocation_path = minimax_with_alpha_beta(\n",
        "                    fire_levels, road_blockages, path, depth + 1, remaining_fire_units - fire_alloc, remaining_police_units - police_alloc,\n",
        "                    False, alpha, beta, fire_allocation_path + [(region, fire_alloc)], police_allocation_path + [(region, police_alloc)]\n",
        "                )\n",
        "\n",
        "                # Revert changes to fire and road blockages for the next iteration\n",
        "                fire_levels[region] += 10 * fire_alloc\n",
        "                road_blockages[region] += 10 * police_alloc\n",
        "\n",
        "                # Update the maximum evaluation value and best paths if a better evaluation is found\n",
        "                if eval_value > max_eval:\n",
        "                    max_eval = eval_value\n",
        "                    best_fire_allocation_path = new_fire_allocation_path\n",
        "                    best_police_allocation_path = new_police_allocation_path\n",
        "\n",
        "                # Update alpha value for pruning\n",
        "                alpha = max(alpha, eval_value)\n",
        "                # Prune branches where the current value exceeds the beta threshold\n",
        "                if beta <= alpha:\n",
        "                    break\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "\n",
        "        return max_eval, best_fire_allocation_path, best_police_allocation_path\n",
        "\n",
        "    # Minimizing player's turn (Worsen the conditions by simulating damage)\n",
        "    else:\n",
        "        min_eval = float('inf')  # Initialize minimum evaluation value to positive infinity\n",
        "        best_fire_allocation_path = None  # Best allocation path for fire units\n",
        "        best_police_allocation_path = None  # Best allocation path for police units\n",
        "\n",
        "        # Iterate over possible worsening of conditions (fire and blockage worsening)\n",
        "        for fire_worsen in range(0, min(remaining_fire_units, 2) + 1):\n",
        "            for blockage_worsen in range(0, min(remaining_police_units, 2) + 1):\n",
        "                region = path[depth]  # Get current region from the path\n",
        "\n",
        "                # Increase fire and road blockage levels to simulate worsening conditions\n",
        "                fire_levels[region] = min(100, fire_levels[region] + 10 * fire_worsen)\n",
        "                road_blockages[region] = min(100, road_blockages[region] + 10 * blockage_worsen)\n",
        "\n",
        "                # Recursively call Minimax for the next depth (Max player's turn)\n",
        "                eval_value, new_fire_allocation_path, new_police_allocation_path = minimax_with_alpha_beta(\n",
        "                    fire_levels, road_blockages, path, depth + 1, remaining_fire_units, remaining_police_units,\n",
        "                    True, alpha, beta, fire_allocation_path, police_allocation_path\n",
        "                )\n",
        "\n",
        "                # Revert changes to fire and road blockages for the next iteration\n",
        "                fire_levels[region] -= 10 * fire_worsen\n",
        "                road_blockages[region] -= 10 * blockage_worsen\n",
        "\n",
        "                # Update the minimum evaluation value and best paths if a lower evaluation is found\n",
        "                if eval_value < min_eval:\n",
        "                    min_eval = eval_value\n",
        "                    best_fire_allocation_path = new_fire_allocation_path\n",
        "                    best_police_allocation_path = new_police_allocation_path\n",
        "\n",
        "                # Update beta value for pruning\n",
        "                beta = min(beta, eval_value)\n",
        "                # Prune branches where the current value is lower than or equal to the alpha threshold\n",
        "                if beta <= alpha:\n",
        "                    break\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "\n",
        "        return min_eval, best_fire_allocation_path, best_police_allocation_path\n",
        "\n",
        "\n",
        "# Run Minimax with Alpha-Beta Pruning using final fire and blockage levels after Task 2\n",
        "best_value, best_fire_allocation_path, best_police_allocation_path = minimax_with_alpha_beta(\n",
        "    fire_levels=final_fire_levels.copy(),\n",
        "    road_blockages=final_road_blockages.copy(),\n",
        "    path=best_fire_path,\n",
        "    depth=0,\n",
        "    remaining_fire_units=MAX_FIRE_UNITS,\n",
        "    remaining_police_units=MAX_POLICE_UNITS,\n",
        "    is_max_turn=True,\n",
        "    alpha=float('-inf'),\n",
        "    beta=float('inf'),\n",
        "    fire_allocation_path=[],\n",
        "    police_allocation_path=[]\n",
        ")\n",
        "\n",
        "region_names = {0: 'R1', 1: 'R2', 2: 'R3', 3: 'R4', 4: 'R5'}  # the region names\n",
        "\n",
        "\n",
        "def allocate_units_recursive(path, depth, remaining_units, current_allocation, all_allocations, unit_type=\"fire\"):\n",
        "    \"\"\"\n",
        "    Recursive function to compute all possible allocations of units along the given path.\n",
        "    The printed data represents different possible resource allocation scenarios for fire trucks and police units across regions in a\n",
        "    disaster scenario. Each list shows how units are distributed to address fires and road blockages,\n",
        "    with each tuple (region_index, units_allocated) indicating the number of units assigned to a specific region along the path.\n",
        "\n",
        "\n",
        "\n",
        "    Parameters:\n",
        "    - path: List of regions in the order of travel.\n",
        "    - depth: Current depth in the allocation path (region index in path).\n",
        "    - remaining_units: Number of remaining units available.\n",
        "    - current_allocation: Current allocation path being explored.\n",
        "    - all_allocations: List to store all possible allocation paths.\n",
        "    - unit_type: Type of unit being allocated (\"fire\" or \"police\").\n",
        "    \"\"\"\n",
        "    # Base case: If we've allocated units for all regions along the path\n",
        "    if depth == len(path):\n",
        "        all_allocations.append(current_allocation.copy())\n",
        "        return\n",
        "\n",
        "    # Get the current region to allocate units\n",
        "    region = path[depth]\n",
        "\n",
        "    # Iterate over all possible allocations of units for this region\n",
        "    for unit_alloc in range(remaining_units + 1):\n",
        "        # Add current allocation to the path\n",
        "        current_allocation.append((region, unit_alloc))\n",
        "\n",
        "        # Recursively allocate units for the next region in the path\n",
        "        allocate_units_recursive(\n",
        "            path=path,\n",
        "            depth=depth + 1,\n",
        "            remaining_units=remaining_units - unit_alloc,\n",
        "            current_allocation=current_allocation,\n",
        "            all_allocations=all_allocations,\n",
        "            unit_type=unit_type\n",
        "        )\n",
        "\n",
        "        # Remove the current allocation to backtrack\n",
        "        current_allocation.pop()\n",
        "\n",
        "# Wrapper function to initialize and call the recursive allocation function\n",
        "def compute_all_allocations(path, max_units, unit_type=\"fire\"):\n",
        "    \"\"\"\n",
        "    Compute all possible allocations of units along a given path.\n",
        "\n",
        "    Parameters:\n",
        "    - path: List of regions in the order of travel.\n",
        "    - max_units: Maximum number of units available.\n",
        "    - unit_type: Type of unit being allocated (\"fire\" or \"police\").\n",
        "\n",
        "    Returns:\n",
        "    - List of all possible allocation paths.\n",
        "    \"\"\"\n",
        "    all_allocations = []  # List to store all possible allocation paths\n",
        "    allocate_units_recursive(\n",
        "        path=path[1:],  # Exclude the starting region (path[0]) from allocation\n",
        "        depth=0,\n",
        "        remaining_units=max_units,\n",
        "        current_allocation=[],\n",
        "        all_allocations=all_allocations,\n",
        "        unit_type=unit_type\n",
        "    )\n",
        "    return all_allocations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0448e2",
      "metadata": {
        "id": "7b0448e2"
      },
      "source": [
        "## Task 4: Game Theory for Multi-Agent Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5c85a2a",
      "metadata": {
        "id": "b5c85a2a"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ You can develop payoff matrices to determine optimal parameter values in this project by selecting the best value from a list of candidate options based on your design. A common approach is to evaluate parameter candidates by testing a range of values in defined steps. For example, the `parameter` can take values from the set `{0, 1, 2, 3, 4}` in steps of 1. Then, the set is a list of actions for one player in game theory. Accordingly, you need to initial a all-zero payoff matrix to compute its payoff values. `payoffs = [[0 for _ in range(len(action_payer1))] for _ in range(len(action_payer2))]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b0b2eb",
      "metadata": {
        "id": "b5b0b2eb"
      },
      "outputs": [],
      "source": [
        "# Task 4: Game Theory for Multi-Agent Systems\n",
        "import numpy as np\n",
        "\n",
        "# Goal:\n",
        "# Apply game theory to analyze and identify optimal strategies for allocating fire trucks and police units.\n",
        "# This analysis helps determine the best resource allocation using Nash Equilibria, Dominant Strategies, and Weak Dominant Strategies.\n",
        "# This builds on the resource allocation paths derived in Task 2 and the overall objective of optimizing rescue operations in Task 3.\n",
        "\n",
        "# Input:\n",
        "# - Fire and police actions (allocation levels).\n",
        "# - Initial fire levels and road blockages.\n",
        "# - Payoff matrix representing the outcomes of different actions.\n",
        "\n",
        "# Output:\n",
        "# - Payoff matrix showing utility values for each combination of fire and police actions.\n",
        "# - Nash Equilibria, Dominant Strategies, and Weak Dominant Strategies.\n",
        "\n",
        "# Next Step:\n",
        "# Use the findings from this analysis to optimize multi-agent decision-making in the rescue operation (integrate with Bayesian analysis from Task 5).\n",
        "\n",
        "# Define possible actions for fire trucks and police trucks\n",
        "fire_actions = list(range(MAX_FIRE_UNITS + 1))  # Actions: Allocate between 0 and MAX_FIRE_UNITS fire trucks\n",
        "police_actions = list(range(MAX_POLICE_UNITS + 1))  # Actions: Allocate between 0 and MAX_POLICE_UNITS police units\n",
        "\n",
        "# Initialize the payoff matrix (all-zero matrix initially)\n",
        "payoff_matrix = np.zeros((len(fire_actions), len(police_actions)))  # Create a matrix to store utility values for each action combination\n",
        "\n",
        "# Populate the payoff matrix based on utility values\n",
        "def calculate_payoff(fire_alloc, police_alloc, fire_levels, road_blockages):\n",
        "    \"\"\"\n",
        "    Calculate the payoff for a given allocation of fire and police units.\n",
        "\n",
        "    Parameters:\n",
        "    fire_alloc (int): Number of fire units allocated.\n",
        "    police_alloc (int): Number of police units allocated.\n",
        "    fire_levels (list): List of fire levels in each region.\n",
        "    road_blockages (list): List of road blockage levels in each region.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated utility value for the given allocation.\n",
        "    \"\"\"\n",
        "    # Create temporary copies of fire and road blockage levels\n",
        "    temp_fire_levels = fire_levels.copy()  # Temporary fire levels after allocation\n",
        "    temp_road_blockages = road_blockages.copy()  # Temporary road blockage levels after allocation\n",
        "\n",
        "    # Update fire and road blockage levels based on allocations\n",
        "    for region in range(5):  # Loop through each region\n",
        "        temp_fire_levels[region] = max(0, temp_fire_levels[region] - 10 * fire_alloc)  # Reduce fire levels by 10% per fire unit allocated\n",
        "        temp_road_blockages[region] = max(0, temp_road_blockages[region] - 10 * police_alloc)  # Reduce road blockages by 10% per police unit allocated\n",
        "\n",
        "    # Introduce a penalty for high damage levels after allocation\n",
        "    penalty = sum(50 if (temp_fire_levels[r] > 50 or temp_road_blockages[r] > 50) else 0 for r in range(5))  # Add penalty for high damage levels\n",
        "\n",
        "    # Calculate utility based on adjusted priority for high, medium, and low damage levels\n",
        "    utility = 0  # Initialize utility value\n",
        "    for region in range(5):  # Loop through each region\n",
        "        # Assign priority factor based on the level of damage\n",
        "        if temp_fire_levels[region] >= 30 or temp_road_blockages[region] >= 50:\n",
        "            priority_factor = 10  # High damage priority (critical regions)\n",
        "        elif temp_fire_levels[region] >= 10 or temp_road_blockages[region] >= 10:\n",
        "            priority_factor = 5  # Medium damage priority\n",
        "        else:\n",
        "            priority_factor = 2  # Low damage priority\n",
        "\n",
        "        # Calculate utility for the region based on reduced damage levels\n",
        "        utility += priority_factor * ((100 - temp_fire_levels[region]) + (100 - temp_road_blockages[region]))\n",
        "\n",
        "    return utility - penalty  # Return the calculated utility value minus penalty\n",
        "\n",
        "# Calculate payoffs for each combination of actions\n",
        "for i, fire_alloc in enumerate(fire_actions):  # Loop through fire allocation actions\n",
        "    for j, police_alloc in enumerate(police_actions):  # Loop through police allocation actions\n",
        "        payoff_matrix[i][j] = calculate_payoff(fire_alloc, police_alloc, initial_fire_levels, initial_road_blockages)  # Populate payoff matrix with calculated values\n",
        "\n",
        "\n",
        "# Identifying Nash Equilibrium, Dominant Strategy, and Weak Dominant Strategy\n",
        "def find_nash_equilibrium(matrix):\n",
        "    \"\"\"\n",
        "    Identify Nash Equilibria in the given payoff matrix.\n",
        "\n",
        "    Parameters:\n",
        "    matrix (ndarray): The payoff matrix.\n",
        "\n",
        "    Returns:\n",
        "    list: List of tuples representing Nash Equilibria (fire units, police units).\n",
        "    \"\"\"\n",
        "    fire_best_responses = np.argmax(matrix, axis=0)  # Best response for fire allocation for each police action\n",
        "    police_best_responses = np.argmax(matrix, axis=1)  # Best response for police allocation for each fire action\n",
        "    nash_equilibria = []  # List to store Nash Equilibria\n",
        "    for i in range(matrix.shape[0]):  # Loop through fire actions\n",
        "        for j in range(matrix.shape[1]):  # Loop through police actions\n",
        "            if fire_best_responses[j] == i and police_best_responses[i] == j:  # Check if both players are best responding\n",
        "                nash_equilibria.append((i, j))  # Append Nash Equilibrium if conditions are met\n",
        "    return nash_equilibria  # Return list of Nash Equilibria\n",
        "\n",
        "nash_equilibria = find_nash_equilibrium(payoff_matrix)  # Find Nash Equilibria\n",
        "\n",
        "\n",
        "# Dominant Strategy Equilibrium\n",
        "def find_dominant_strategy(matrix):\n",
        "    \"\"\"\n",
        "    Identify if there is a dominant strategy for both players.\n",
        "\n",
        "    Parameters:\n",
        "    matrix (ndarray): The payoff matrix.\n",
        "\n",
        "    Returns:\n",
        "    list: List of dominant strategies for fire and police players.\n",
        "    \"\"\"\n",
        "    dominant_strategy = []  # List to store dominant strategies\n",
        "    for i in range(matrix.shape[0]):  # Loop through fire actions\n",
        "        # Check if the current row is greater or equal to all other rows\n",
        "        if all((matrix[i, :] >= matrix[j, :]).all() for j in range(matrix.shape[0]) if j != i):\n",
        "            dominant_strategy.append((i, \"Fire\"))  # Append dominant strategy for fire player\n",
        "    for j in range(matrix.shape[1]):  # Loop through police actions\n",
        "        # Check if the current column is greater or equal to all other columns\n",
        "        if all((matrix[:, j] >= matrix[:, k]).all() for k in range(matrix.shape[1]) if k != j):\n",
        "            dominant_strategy.append((j, \"Police\"))  # Append dominant strategy for police player\n",
        "    return dominant_strategy  # Return list of dominant strategies\n",
        "\n",
        "dominant_strategies = find_dominant_strategy(payoff_matrix)  # Find dominant strategies\n",
        "\n",
        "# Weak Dominant Strategy Equilibrium\n",
        "def find_weak_dominant_strategy(matrix):\n",
        "    \"\"\"\n",
        "    Identify weak dominant strategies for both players.\n",
        "\n",
        "    Parameters:\n",
        "    matrix (ndarray): The payoff matrix.\n",
        "\n",
        "    Returns:\n",
        "    list: List of weak dominant strategies for fire and police players.\n",
        "    \"\"\"\n",
        "    weak_dominant_strategy = []  # List to store weak dominant strategies\n",
        "    for i in range(matrix.shape[0]):  # Loop through fire actions\n",
        "        # Check if the current row is greater or equal to all other rows and greater in at least one case\n",
        "        if all((matrix[i, :] >= matrix[j, :]).all() for j in range(matrix.shape[0]) if j != i) and any((matrix[i, :] > matrix[j, :]).any() for j in range(matrix.shape[0]) if j != i):\n",
        "            weak_dominant_strategy.append((i, \"Fire\"))  # Append weak dominant strategy for fire player\n",
        "    for j in range(matrix.shape[1]):  # Loop through police actions\n",
        "        # Check if the current column is greater or equal to all other columns and greater in at least one case\n",
        "        if all((matrix[:, j] >= matrix[:, k]).all() for k in range(matrix.shape[1]) if k != j) and any((matrix[:, j] > matrix[:, k]).any() for k in range(matrix.shape[1]) if k != j):\n",
        "            weak_dominant_strategy.append((j, \"Police\"))  # Append weak dominant strategy for police player\n",
        "    return weak_dominant_strategy  # Return list of weak dominant strategies\n",
        "\n",
        "weak_dominant_strategies = find_weak_dominant_strategy(payoff_matrix)  # Find weak dominant strategies\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1LQmLw4eUd7N",
      "metadata": {
        "id": "1LQmLw4eUd7N"
      },
      "outputs": [],
      "source": [
        "# Task 4: Game Theory for Multi-Agent Systems\n",
        "import numpy as np\n",
        "\n",
        "# Goal:\n",
        "# Apply game theory to analyze and identify optimal strategies for allocating fire trucks and police units.\n",
        "# This analysis helps determine the best resource allocation using Nash Equilibria, Dominant Strategies, and Weak Dominant Strategies.\n",
        "# This builds on the resource allocation paths derived in Task 2 and the overall objective of optimizing rescue operations in Task 3.\n",
        "\n",
        "# Input:\n",
        "# - Fire and police actions (allocation levels).\n",
        "# - Initial fire levels and road blockages.\n",
        "# - Payoff matrix representing the outcomes of different actions.\n",
        "\n",
        "# Output:\n",
        "# - Payoff matrix showing utility values for each combination of fire and police actions.\n",
        "# - Nash Equilibria, Dominant Strategies, and Weak Dominant Strategies.\n",
        "\n",
        "# Next Step:\n",
        "# Use the findings from this analysis to optimize multi-agent decision-making in the rescue operation (integrate with Bayesian analysis from Task 5).\n",
        "\n",
        "# Define possible actions for fire trucks and police trucks\n",
        "\n",
        "# Define possible actions for fire trucks and police trucks\n",
        "fire_actions = list(range(MAX_FIRE_UNITS + 1))  # Actions: Allocate between 0 and MAX_FIRE_UNITS fire trucks\n",
        "police_actions = list(range(MAX_POLICE_UNITS + 1))  # Actions: Allocate between 0 and MAX_POLICE_UNITS police units\n",
        "\n",
        "# Initialize the payoff matrix (all-zero matrix initially)\n",
        "payoff_matrix = np.zeros((len(fire_actions), len(police_actions)))\n",
        "\n",
        "# Task 4: Game Theory for Multi-Agent Systems\n",
        "import numpy as np\n",
        "\n",
        "# Define possible actions for fire trucks and police trucks\n",
        "fire_actions = list(range(MAX_FIRE_UNITS + 1))  # Actions: Allocate between 0 and MAX_FIRE_UNITS fire trucks\n",
        "police_actions = list(range(MAX_POLICE_UNITS + 1))  # Actions: Allocate between 0 and MAX_POLICE_UNITS police units\n",
        "\n",
        "# Initialize the payoff matrix (all-zero matrix initially)\n",
        "payoff_matrix = np.zeros((len(fire_actions), len(police_actions)))\n",
        "\n",
        "# Populate the payoff matrix based on utility values\n",
        "def calculate_payoff(fire_alloc, police_alloc, fire_levels, road_blockages):\n",
        "    \"\"\"\n",
        "      Calculate the payoff value for a given allocation of fire trucks and police units.\n",
        "\n",
        "      Args:\n",
        "          fire_alloc (int): Number of fire trucks allocated to each region.\n",
        "          police_alloc (int): Number of police units allocated to each region.\n",
        "          fire_levels (list): Initial fire levels for each region.\n",
        "          road_blockages (list): Initial road blockage levels for each region.\n",
        "\n",
        "      Returns:\n",
        "          int: The payoff value, which represents the effectiveness of the allocation in mitigating fire and road blockages.\n",
        "      \"\"\"\n",
        "    temp_fire_levels = fire_levels.copy()\n",
        "    temp_road_blockages = road_blockages.copy()\n",
        "\n",
        "    for region in range(5):\n",
        "        temp_fire_levels[region] = max(0, temp_fire_levels[region] - 10 * fire_alloc)\n",
        "        temp_road_blockages[region] = max(0, temp_road_blockages[region] - 10 * police_alloc)\n",
        "\n",
        "    # Introduce a penalty for high damage levels after allocation\n",
        "    penalty = sum(50 if (temp_fire_levels[r] > 50 or temp_road_blockages[r] > 50) else 0 for r in range(5))\n",
        "    return calculate_utility(temp_fire_levels, temp_road_blockages, best_fire_path) - penalty\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate utility based on adjusted priority for high, medium, and low damage levels\n",
        "    utility = 0\n",
        "    for region in range(5):\n",
        "        if temp_fire_levels[region] >= 30 or temp_road_blockages[region] >= 50:\n",
        "            priority_factor = 10  # High damage priority (critical regions)\n",
        "        elif temp_fire_levels[region] >= 10 or temp_road_blockages[region] >= 10:\n",
        "            priority_factor = 5  # Medium damage priority\n",
        "        else:\n",
        "            priority_factor = 2  # Low damage priority\n",
        "\n",
        "        utility += priority_factor * ((100 - temp_fire_levels[region]) + (100 - temp_road_blockages[region]))\n",
        "\n",
        "    return utility - penalty\n",
        "\n",
        "# Calculate payoffs for each combination of actions\n",
        "for i, fire_alloc in enumerate(fire_actions):\n",
        "    for j, police_alloc in enumerate(police_actions):\n",
        "        payoff_matrix[i][j] = calculate_payoff(fire_alloc, police_alloc, initial_fire_levels, initial_road_blockages)\n",
        "\n",
        "# Print the payoff matrix\n",
        "\n",
        "\n",
        "# Find the best strategy (e.g., Nash Equilibrium)\n",
        "best_fire_action, best_police_action = np.unravel_index(np.argmax(payoff_matrix, axis=None), payoff_matrix.shape)\n",
        "\n",
        "\n",
        "# Identifying Nash Equilibrium, Dominant Strategy, and Weak Dominant Strategy\n",
        "def find_nash_equilibrium(matrix):\n",
        "    \"\"\"Identify Nash Equilibria in the given payoff matrix.\"\"\"\n",
        "    fire_best_responses = np.argmax(matrix, axis=0)\n",
        "    police_best_responses = np.argmax(matrix, axis=1)\n",
        "    nash_equilibria = []\n",
        "    for i in range(matrix.shape[0]):\n",
        "        for j in range(matrix.shape[1]):\n",
        "            if fire_best_responses[j] == i and police_best_responses[i] == j:\n",
        "                nash_equilibria.append((i, j))\n",
        "    return nash_equilibria\n",
        "\n",
        "nash_equilibria = find_nash_equilibrium(payoff_matrix)\n",
        "\n",
        "\n",
        "# Dominant Strategy Equilibrium\n",
        "def find_dominant_strategy(matrix):\n",
        "    \"\"\"Identify if there is a dominant strategy for both players.\"\"\"\n",
        "    dominant_strategy = []\n",
        "    for i in range(matrix.shape[0]):\n",
        "        if all((matrix[i, :] >= matrix[j, :]).all() for j in range(matrix.shape[0]) if j != i):\n",
        "            dominant_strategy.append((i, \"Fire\"))\n",
        "    for j in range(matrix.shape[1]):\n",
        "        if all((matrix[:, j] >= matrix[:, k]).all() for k in range(matrix.shape[1]) if k != j):\n",
        "            dominant_strategy.append((j, \"Police\"))\n",
        "    return dominant_strategy\n",
        "\n",
        "dominant_strategies = find_dominant_strategy(payoff_matrix)\n",
        "\n",
        "\n",
        "# Weak Dominant Strategy Equilibrium\n",
        "def find_weak_dominant_strategy(matrix):\n",
        "    \"\"\"Identify weak dominant strategies for both players.\"\"\"\n",
        "    weak_dominant_strategy = []\n",
        "    for i in range(matrix.shape[0]):\n",
        "        if all((matrix[i, :] >= matrix[j, :]).all() for j in range(matrix.shape[0]) if j != i) and any((matrix[i, :] > matrix[j, :]).any() for j in range(matrix.shape[0]) if j != i):\n",
        "            weak_dominant_strategy.append((i, \"Fire\"))\n",
        "    for j in range(matrix.shape[1]):\n",
        "        if all((matrix[:, j] >= matrix[:, k]).all() for k in range(matrix.shape[1]) if k != j) and any((matrix[:, j] > matrix[:, k]).any() for k in range(matrix.shape[1]) if k != j):\n",
        "            weak_dominant_strategy.append((j, \"Police\"))\n",
        "    return weak_dominant_strategy\n",
        "\n",
        "weak_dominant_strategies = find_weak_dominant_strategy(payoff_matrix)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a42b2d7",
      "metadata": {
        "id": "6a42b2d7"
      },
      "source": [
        "## Task 5: Bayesian Networks for Uncertain Inferences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc1b99e",
      "metadata": {
        "id": "5bc1b99e"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ Given a rescue scenario and a specific path, what are the variables to consider? Based on the available information, you will need to construct the topology of a Bayesian network, identifying dependencies between the variables, and then calculate the Conditional Probability Tables (CPTs) for each node in the network. Finally, make the inference contribute to the rescue optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Du051XSIWJKH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du051XSIWJKH",
        "outputId": "fc895a03-8c73-455d-c691-cad5e174e0a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.10/dist-packages (0.1.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.2.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.5.0+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install pgmpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DuKQzmCgXj0j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuKQzmCgXj0j",
        "outputId": "aaf60fbd-873e-40eb-a4a0-c80de06c1266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n"
          ]
        }
      ],
      "source": [
        "# Task 5: Bayesian Networks for Uncertain Inferences\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Goal:\n",
        "# Develop Bayesian Networks to handle uncertainties in rescue operations, such as fire spread or road blockages.\n",
        "# This task helps to make informed decisions under uncertainty, integrating the optimization insights from Tasks 1-4.\n",
        "\n",
        "# Input:\n",
        "# - Network structure defining relationships between key events (fire spread, aftershocks, damage levels).\n",
        "# - Conditional Probability Tables (CPTs) representing the likelihood of each event.\n",
        "\n",
        "# Output:\n",
        "# - Probabilistic inference results that help optimize rescue operations.\n",
        "\n",
        "# Next Step:\n",
        "# Use these probabilistic insights to dynamically adjust resource allocation strategies identified in Task 4.\n",
        "\n",
        "# Define the structure of the Bayesian Network for each region\n",
        "edges = []\n",
        "for region in range(1, 6):\n",
        "    edges.extend([\n",
        "        (f'FireSpread_R{region}', f'FireDamage_R{region}'),\n",
        "        (f'Aftershock_R{region}', f'RoadBlockage_R{region}')\n",
        "    ])\n",
        "\n",
        "model = BayesianModel(edges)  # Define relationships between nodes in the Bayesian Network\n",
        "\n",
        "# Define the Conditional Probability Tables (CPTs) for each region\n",
        "cpds = []\n",
        "for region in range(1, 6):\n",
        "    cpd_fire_spread = TabularCPD(variable=f'FireSpread_R{region}', variable_card=2, values=[[0.6], [0.4]])  # CPT for FireSpread\n",
        "    cpd_aftershock = TabularCPD(variable=f'Aftershock_R{region}', variable_card=2, values=[[0.7], [0.3]])  # CPT for Aftershock\n",
        "    cpd_fire_damage = TabularCPD(variable=f'FireDamage_R{region}', variable_card=2,\n",
        "                                 values=[[0.8, 0.3], [0.2, 0.7]],\n",
        "                                 evidence=[f'FireSpread_R{region}'], evidence_card=[2])  # CPT for FireDamage given FireSpread\n",
        "    cpd_road_blockage = TabularCPD(variable=f'RoadBlockage_R{region}', variable_card=2,\n",
        "                                   values=[[0.9, 0.4], [0.1, 0.6]],\n",
        "                                   evidence=[f'Aftershock_R{region}'], evidence_card=[2])  # CPT for RoadBlockage given Aftershock\n",
        "\n",
        "    cpds.extend([cpd_fire_spread, cpd_aftershock, cpd_fire_damage, cpd_road_blockage])\n",
        "\n",
        "# Add CPTs to the model\n",
        "model.add_cpds(*cpds)  # Add defined CPTs to the Bayesian model\n",
        "\n",
        "# Verify the model\n",
        "assert model.check_model(), \"The Bayesian network model is invalid\"  # Verify if the model is correct\n",
        "\n",
        "# Perform inference\n",
        "inference = VariableElimination(model)  # Create an inference object for performing queries\n",
        "\n",
        "\n",
        "# Link to Previous Tasks:\n",
        "# - This task builds on the optimization strategies in Task 3, where dynamic conditions such as fire spread and road blockages were modeled.\n",
        "# - Task 5 uses probabilistic models to provide insights into uncertainties, which can then inform the game-theoretic strategies analyzed in Task 4.\n",
        "# - The Bayesian network helps in making real-time adjustments to the rescue paths derived in Task 2, especially under changing conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "184c5e07",
      "metadata": {
        "id": "184c5e07"
      },
      "source": [
        "# Overall Running"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6697bf4",
      "metadata": {
        "id": "a6697bf4"
      },
      "source": [
        "You need to provide the overall rescure results by code running based on your overall design and breakdown task designs. It is preferred to put `functions` in the breakdown task above and execute them in the overall running here.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UEODmNADaEqd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "UEODmNADaEqd",
        "outputId": "b8ed5dce-bc50-4305-a427-1e4e0604d7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1: Genetic Algorithm to find the best paths for rescue teams\n",
            "Best 10 Paths for Fire Trucks in Genetic Algorithms:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'fire_truck_best_paths' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2915c7f60cf5>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Execute the integrated rescue process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mintegrated_rescue_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-2915c7f60cf5>\u001b[0m in \u001b[0;36mintegrated_rescue_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Task 1: Genetic Algorithm to find the best paths for rescue teams\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best 10 Paths for Fire Trucks in Genetic Algorithms:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfire_truck_best_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mreadable_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mREVERSE_REGION_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSTART_LOCATIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fire_truck'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSTART_LOCATIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fire_truck'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadable_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fitness (Total Time):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fire_truck_best_paths' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Function to integrate the entire rescue process across all tasks\n",
        "def integrated_rescue_process():\n",
        "\n",
        "    print (\"Task 1: Genetic Algorithm to find the best paths for rescue teams\")\n",
        "    print(\"Best 10 Paths for Fire Trucks in Genetic Algorithms:\")\n",
        "    for path, time in fire_truck_best_paths:\n",
        "        readable_path = [REVERSE_REGION_MAP[region] for region in [START_LOCATIONS['fire_truck']] + list(path) + [START_LOCATIONS['fire_truck']]]\n",
        "        print(\"Path:\", readable_path, \"Fitness (Total Time):\", time)\n",
        "\n",
        "    print(\"\\nBest 10 Paths for Police Trucks in Genetic Algorithms:\")\n",
        "    for path, time in police_truck_best_paths:\n",
        "        readable_path = [REVERSE_REGION_MAP[region] for region in [START_LOCATIONS['police_truck']] + list(path) + [START_LOCATIONS['police_truck']]]\n",
        "        print(\"Path:\", readable_path, \"Fitness (Total Time):\", time)\n",
        "    print (\"================================================================================================================================\")\n",
        "    print (\"Task 2: Ant Colony Optimization to simulate improved rescue paths\")\n",
        "\n",
        "    print(\"\\nSimulated ACO of best 5 path for Fire Trucks after improving the result in Genetic Algorithms:\")\n",
        "    for path, _ in fire_truck_best_paths[0:5]:\n",
        "        time = simulate_agent_path(path, START_LOCATIONS['fire_truck'], final_fire_levels, final_road_blockages, 'fire_truck')\n",
        "        readable_path = [REVERSE_REGION_MAP[region] for region in path]\n",
        "        print(\"Path:\", readable_path, \"Total Time:\", time)\n",
        "\n",
        "    print(\"\\nSimulated ACO of best 5 path for Police Trucks after improving the result in Genetic Algorithms:\")\n",
        "    for path, _ in police_truck_best_paths[0:5]:\n",
        "        time = simulate_agent_path(path, START_LOCATIONS['police_truck'], final_fire_levels, final_road_blockages, 'police_truck')\n",
        "        readable_path = [REVERSE_REGION_MAP[region] for region in path]\n",
        "        print(\"Path:\", readable_path, \"Total Time:\", time)\n",
        "\n",
        "    # Output the final fire levels after ACO\n",
        "    print(\"\\nFinal Fire Levels after Task 2:\", final_fire_levels)\n",
        "    print(\"\\nFinal Road Blockages after Task 2:\", final_road_blockages)\n",
        "    print (\"================================================================================================================================\")\n",
        "    print (\"Task 3: Minimax with Alpha-Beta Pruning to allocate rescue units\")\n",
        "    print(\"\\nBest utility value:\", best_value)\n",
        "    print(\"\\nBest allocation of fire truck units per region:\")\n",
        "    fire_unit_distribution = {region: 1 for region in range(5)}  # Initial 1 unit per region\n",
        "    for region, units in best_fire_allocation_path:\n",
        "        fire_unit_distribution[region] += units - 1  # Adjust by -1 to avoid double-counting initial allocation\n",
        "\n",
        "    for region, units in fire_unit_distribution.items():\n",
        "        print(f\"Region {region_names[region]}: {units} fire units\")\n",
        "\n",
        "    print(\"\\nBest allocation of police units per region:\")\n",
        "    police_unit_distribution = {region: 1 for region in range(5)}  # Initial 1 unit per region\n",
        "\n",
        "\n",
        "    # Separate paths for fire trucks and police units\n",
        "    best_fire_path = fire_truck_best_paths[0][0]  # Best path for fire trucks (from Task 2)\n",
        "    best_police_path = police_truck_best_paths[0][0]  # Best path for police trucks (from Task 2)\n",
        "\n",
        "    # Compute all possible allocations along each path\n",
        "    fire_allocations = compute_all_allocations(best_fire_path, MAX_FIRE_UNITS, unit_type=\"fire\")\n",
        "    police_allocations = compute_all_allocations(best_police_path, MAX_POLICE_UNITS, unit_type=\"police\")\n",
        "\n",
        "    # Display the first 20 possible allocation paths for fire trucks\n",
        "    print(\"First 20 possible fire truck allocations:\")\n",
        "    for allocation in fire_allocations[:20]:  # Only print out the first 20 for brevity\n",
        "        print(allocation)\n",
        "\n",
        "    # Display the first 20 possible allocation paths for police units\n",
        "    print(\"\\nFirst 20 possible police unit allocations:\")\n",
        "    for allocation in police_allocations[:20]:  # Only print out the first 20 for brevity\n",
        "        print(allocation)\n",
        "    print (\"================================================================================================================================\")\n",
        "    print (\"Task 4: Game Theory for optimal allocation strategies\")\n",
        "    # Print the payoff matrix\n",
        "    print(\"\\nPayoff Matrix:\")\n",
        "    print(payoff_matrix)  # Display the payoff matrix showing the utility values for each combination of actions\n",
        "\n",
        "    # Find the best strategy (e.g., Nash Equilibrium)\n",
        "    best_fire_action, best_police_action = np.unravel_index(np.argmax(payoff_matrix, axis=None), payoff_matrix.shape)  # Find the best combination of fire and police units\n",
        "    print(f\"\\nBest Strategy: Allocate {best_fire_action} fire units and {best_police_action} police units for optimal outcome.\")\n",
        "\n",
        "    print(\"\\nNash Equilibria:\")\n",
        "    for fire_units, police_units in nash_equilibria:  # Loop through Nash Equilibria\n",
        "        print(f\"Allocate {fire_units} fire units and {police_units} police units\")  # Print each Nash Equilibrium\n",
        "\n",
        "    print(\"\\nDominant Strategies:\")\n",
        "    for strategy, player in dominant_strategies:  # Loop through dominant strategies\n",
        "        print(f\"Player {player} has a dominant strategy of allocating {strategy} units\")  # Print each dominant strategy\n",
        "\n",
        "    print(\"\\nWeak Dominant Strategies:\")\n",
        "    for strategy, player in weak_dominant_strategies:  # Loop through weak dominant strategies\n",
        "        print(f\"Player {player} has a weak dominant strategy of allocating {strategy} units\")  # Print each weak dominant strategy\n",
        "    print (\"================================================================================================================================\")\n",
        "    print (\"Task 5: Bayesian Networks to provide probabilistic insights\")\n",
        "    # Query the probability of FireDamage given FireSpread for each region\n",
        "    for region in range(1, 6):\n",
        "        query_result = inference.query(variables=[f'FireDamage_R{region}'], evidence={f'FireSpread_R{region}': 1})\n",
        "        print(f\"\\nProbability of FireDamage in R{region} given FireSpread:\")\n",
        "        print(query_result)\n",
        "\n",
        "    # Query the probability of RoadBlockage given Aftershock for each region\n",
        "    for region in range(1, 6):\n",
        "        query_result = inference.query(variables=[f'RoadBlockage_R{region}'], evidence={f'Aftershock_R{region}': 1})\n",
        "        print(f\"\\nProbability of RoadBlockage in R{region} given Aftershock:\")\n",
        "        print(query_result)\n",
        "\n",
        "# Execute the integrated rescue process\n",
        "integrated_rescue_process()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b121817",
      "metadata": {
        "id": "7b121817"
      },
      "source": [
        "## Summary of Results:\n",
        "The integrated simulation of rescue operations in NovaCity (covering Tasks 1 to 5) represents a well-rounded strategy for optimizing emergency resource allocation. By employing multiple algorithms, we addressed different aspects of the complex rescue scenario, leading to a series of important findings that highlight the efficiency and adaptability of the proposed framework.\n",
        "\n",
        "Best Rescue Paths (Tasks 1 & 2)\n",
        "\n",
        "The Genetic Algorithm (GA) identified multiple feasible paths for both fire trucks and police units, with total fitness times ranging from approximately 71 to 84 minutes. These diverse routes provided flexibility in the planning of the rescue operation, allowing the selection of optimal paths based on various conditions. To further enhance these paths, Ant Colony Optimization (ACO) was applied, resulting in significant reductions in travel time for most routes. For example, fire truck paths that originally ranged from 71 to 84 minutes were improved with ACO, achieving travel times between 15 and 26 minutes. The ACO method utilized pheromone levels and heuristic factors to adapt routes dynamically, showing its effectiveness in refining rescue logistics.\n",
        "\n",
        "Final Damage Status (Task 2)\n",
        "\n",
        "The application of ACO resulted in the complete suppression of fires and removal of road blockages across all regions. This is evidenced by the final fire levels and road blockages in each of the five regions being reduced to zero. This result reflects the efficiency of the resource allocation strategies and the successful coordination of rescue units in mitigating all immediate threats, thus fully restoring accessibility in the affected areas.\n",
        "\n",
        "\n",
        "\n",
        "Resource Allocation (Task 3)\n",
        "\n",
        "Using Minimax with Alpha-Beta Pruning, fire trucks and police units were strategically allocated to different regions based on utility maximization. Region R1 received the highest allocation of fire trucks, with 5 units assigned, Region 4 receieved 2 fire units which is the second highest level,whereas Regions R3 through R5 received 1 each. Similarly, for police units, Region R1 received 3 units and R4 recived 2 units, which was higher than the allocations to other regions. This indicates that Region R2 and R4 required a more significant response, likely due to higher initial damage levels, which necessitated prioritization to prevent further escalation of risk. This fits the instruction such that R2 and R4 have higher fire level.\n",
        "\n",
        "However,we found out the region R2 received fewer resources compared to R1, despite having high fire levels, because the utility model prioritized a combination of fire and road blockage risks. Region R1 exhibited significant challenges in both aspects, prompting a higher resource allocation to prevent escalation. However, this approach may have limitations in accounting for individual factors, like high fire risk alone, which led to R2 being comparatively under-prioritized. This suggests a potential flaw in the model where the utility function does not fully adapt to evolving risk scenarios, potentially resulting in an uneven response that could impact the overall rescue operation's effectiveness.\n",
        "\n",
        "Also,the allocation paths generated for fire trucks and police units explore different ways to distribute these resources across critical regions in a disaster-affected area. In the allocation results for fire trucks and police units, each allocation path explores various ways to distribute units across regions in a disaster-affected area.\n",
        "For fire trucks, allocations range from none assigned to any region (minimal allocation) to all 8 trucks assigned to a single region (extreme prioritization). For example, in [(1, 0), (2, 0), (4, 0), (0, 8)], all trucks are allocated to the last region, leaving other areas without support. This approach allows the algorithm to test the impact of prioritizing specific regions over others.\n",
        "Police unit allocations follow a similar pattern, gradually increasing unit assignments to regions. In [(1, 0), (2, 0), (4, 3), (0, 1)], 3 police units are allocated to one region and 1 unit to another, demonstrating flexible prioritization.\n",
        "This systematic exploration of allocation combinations helps identify the most effective way to use limited resources in disaster response.\n",
        "\n",
        "Optimal Strategies (Task 4)\n",
        "\n",
        "The payoff matrix in Task 4 is developed using initial fire and road blockage levels. The strategies are tested based on the path planning results from Task 2 and the resource allocation logic from Task 3.\n",
        "The Game Theory framework in Task 4 is used to evaluate the best combination of fire and police units for optimal rescue operation outcomes. It incorporates the priorities defined in Task 3, ensuring that regions with higher damage are prioritized for resources.\n",
        "\n",
        "The results in Task 4 show that the best strategy is to allocate 4 fire units and 6 police units, resulting in optimal resource distribution, as indicated by the Nash equilibrium. The dominant strategy for fire units lies between allocating 4 to 8 units, while police units achieve optimal outcomes by allocating 6 units. The payoff matrix also supports this conclusion, as allocating these specific amounts provides the highest utility value, ensuring effective response and minimizing disaster impact.\n",
        "\n",
        "\n",
        "Game Theory was employed to determine optimal resource allocation strategies under competitive conditions, where multiple regions competed for limited rescue resources. Weak dominant strategies were identified for both fire trucks and police units. The findings suggested that allocating between 4 and 8 fire units and 6 police units represented weak dominant strategies for each respective player. These strategies offered the best balance between minimizing damage across all regions and optimizing the available resources, ensuring a robust allocation approach that remained effective under a variety of circumstances.\n",
        "\n",
        "Probabilistic Analysis (Task 5)\n",
        "\n",
        "To address uncertainties related to fire spread and aftershocks, Bayesian Networks were used for probabilistic analysis. This analysis provided insights into the likelihood of fire damage and road blockages in each region given specific conditions. For instance, the probability of fire damage given fire spread in Region R1 was found to be 0.7, while the probability of road blockage given an aftershock in the same region was 0.6. These probabilistic insights provide valuable information that could be used to adjust the allocation of rescue units dynamically, ensuring that they are positioned to respond promptly to areas most likely to experience further damage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09b42ef6",
      "metadata": {
        "id": "09b42ef6"
      },
      "source": [
        "## Further discussion and Conclusion:\n",
        "\n",
        "\n",
        "\n",
        "The utilization of a multi-algorithmic approach, incorporating Genetic Algorithms, Ant Colony Optimization (ACO), Minimax, Game Theory, and Bayesian Networks, provided a comprehensive solution to the complex problem of resource allocation in a dynamic environment such as an earthquake-affected city. By integrating multiple computational methods, the rescue operations were designed to be both adaptable and resilient under changing conditions.\n",
        "\n",
        "For example,it is clear that Task 2’s ACO approach offers advantages in real-time adaptability that Task 1’s GA lacks. Task 2 can adjust agent paths dynamically based on current conditions, allowing for reduced travel times and efficient path choices in response to changing disaster conditions. Task 1 provides a foundational path but does not support dynamic adjustments, resulting in more consistent but often longer total times.\n",
        "\n",
        "\n",
        "The effectiveness of each algorithm in this integrated approach was significant. The Genetic Algorithm helped generate a variety of feasible routes for rescue teams, ensuring flexibility in decision-making. Meanwhile, ACO proved instrumental in further refining these paths by minimizing travel time, which contributed to a more efficient and timely rescue process. The use of the Minimax algorithm added a strategic component by optimizing resource allocation even under potentially worst-case conditions, thereby ensuring a balanced distribution of fire trucks and police units across affected regions. Game Theory played an essential role in identifying dominant resource allocation strategies, which was especially useful when prioritizing different regions that competed for limited rescue resources.\n",
        "\n",
        "Dynamic and uncertain conditions in post-disaster scenarios, such as fire spread and aftershocks, were effectively managed using Bayesian Networks. This approach allowed the modeling of such uncertainties and provided insights that were then used to adjust strategies derived from the Minimax algorithm and Game Theory. The integration of probabilistic reasoning with optimization techniques allowed the system to better adapt to unforeseen events, ultimately improving the resilience of the entire rescue operation.\n",
        "\n",
        "\n",
        "However, there are some limitation and in the model as well. While the Minimax model effectively balanced utility to prioritize high-risk areas like R1 and R4, the lower allocation for R2 despite high fire levels suggests that certain aspects of the utility function or risk prioritization criteria could be refined. Incorporating more dynamic and context-specific factors, such as fire spread velocity or critical infrastructure in each region, could potentially lead to a more balanced and context-sensitive allocation strategy.\n",
        "\n",
        "\n",
        "Future Recommendations include focusing on real-time adaptation during the rescue efforts by leveraging the probabilistic insights provided by Bayesian Networks. This would enable the continuous and dynamic adjustment of paths and allocation of rescue units, allowing the operations to be more responsive to changing conditions. Furthermore, future iterations of this approach could consider additional factors, such as population density, critical infrastructure, and resource fatigue, which would further refine the model and improve the quality of decision-making. Finally, while the simulated results from this study offer valuable insights, it is essential to validate these findings with real-world disaster response scenarios. Doing so would strengthen the robustness and reliability of the proposed rescue strategies, enhancing their practical applicability.\n",
        "\n",
        "In conclusion, the combination of different optimization techniques and probabilistic modeling provided a well-rounded framework for planning and executing rescue operations in NovaCity. The results indicate that this integrated approach is highly effective in ensuring thorough regional coverage, minimizing overall rescue times, and adapting efficiently to uncertainties inherent in a post-disaster environment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "smv0bVEwi7RS",
      "metadata": {
        "id": "smv0bVEwi7RS"
      },
      "source": [
        "## Disclaimer:\n",
        "\n",
        "This report was completed with the assistance of artificial intelligence tools. While these tools have significantly aided in the generation of code and explanations, human oversight and critical analysis were integral to the development and validation of the presented work. It is important to note that AI tools are not infallible and may produce incorrect or misleading information. Therefore, the results and conclusions presented in this report should be interpreted with due diligence and further verification."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHpIV3ox6eBS"
      },
      "id": "pHpIV3ox6eBS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}