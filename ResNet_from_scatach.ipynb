{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/A8WWE2nAUQP+9PPIrmPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garylau1/model_training/blob/main/ResNet_from_scatach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Deep learning has revolutionized the field of computer vision, and one of its cornerstone architectures is the Residual Network (ResNet). ResNet-50, a specific variant of this architecture, is widely recognized for its exceptional ability to train deep networks by addressing the vanishing gradient problem. In this project, I aim to implement ResNet-50 from scratch to gain a deeper understanding of its inner workings, layer-by-layer construction, and the overall design principles that make it so effective.\n",
        "\n",
        "The implementation process begins with building the foundational components of ResNet-50, including the Bottleneck blocks, which are the core building blocks of the network. These blocks allow ResNet-50 to achieve remarkable depth while maintaining computational efficiency. Subsequently, I will assemble the other essential layers, such as the convolutional layers, downsampling modules, and fully connected layers, to complete the architecture.\n",
        "\n",
        "Once the architecture is fully constructed, I will demonstrate how to integrate pretrained weights into the custom model. By using pretrained weights, the model can leverage prior knowledge gained from training on large datasets, significantly enhancing its performance and reducing the training time required for new tasks. This final step not only validates the accuracy of the implementation but also showcases the versatility of ResNet-50 when applied to practical problems.\n",
        "\n",
        "Through this project, I aim to develop a thorough understanding of ResNet-50 and its components, while also exploring the practical aspects of transferring knowledge using pretrained weights."
      ],
      "metadata": {
        "id": "_n4F1leNJ6_D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "r-TLSRKzWCyx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#import the torch and nn module I need\n",
        "\n",
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from torch import nn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Bottleneck block\n",
        "\n",
        "The Bottleneck block is a critical component of the ResNet-50 architecture, designed to enhance computational efficiency while maintaining expressive power. This block uses a three-layer structure with 1x1, 3x3, and 1x1 convolutional layers to reduce and restore the feature map dimensions. This approach minimizes the computational cost while retaining the ability to extract complex features.\n",
        "\n",
        "In this implementation, the Bottleneck block supports downsampling and flexible stride configurations, making it adaptable for different stages of the ResNet architecture. Additionally, the shortcut connection allows the network to learn residual mappings, addressing the degradation problem in deep networks.\n",
        "\n",
        "This implementation includes options for downsampling, changing the kernel size, and stride adjustments, enabling seamless integration into deeper ResNet layers."
      ],
      "metadata": {
        "id": "I2AvaUbhLeLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of the Bottleneck block for ResNet.\n",
        "\n",
        "    The Bottleneck block is a three-layer residual block used in ResNet architectures.\n",
        "    It performs dimensionality reduction and restoration using `1x1` convolutions\n",
        "    while applying spatial processing with a `3x3` convolution. A shortcut\n",
        "    connection is added to facilitate residual learning.\n",
        "\n",
        "    Args:\n",
        "        in_channel (int): Number of input channels.\n",
        "        hidden_ (int): Number of intermediate channels (reduced dimension).\n",
        "        out_channel (int): Number of output channels.\n",
        "        kernel_sizes (int): Kernel size for `1x1` convolutions (default: 1).\n",
        "        stride (int): Stride for convolutional layers (default: 1).\n",
        "        downsample (bool): Whether to apply downsampling in the shortcut connection (default: True).\n",
        "        change_kernel (bool): Whether to modify the stride in the `3x3` convolution (default: False).\n",
        "\n",
        "    Attributes:\n",
        "        conv1 (nn.Conv2d): First `1x1` convolution layer for dimensionality reduction.\n",
        "        bn1 (nn.BatchNorm2d): BatchNorm layer for the first convolution.\n",
        "        conv2 (nn.Conv2d): Second `3x3` convolution layer for spatial processing.\n",
        "        bn2 (nn.BatchNorm2d): BatchNorm layer for the second convolution.\n",
        "        conv3 (nn.Conv2d): Third `1x1` convolution layer for dimensionality restoration.\n",
        "        bn3 (nn.BatchNorm2d): BatchNorm layer for the third convolution.\n",
        "        relu (nn.ReLU): ReLU activation function.\n",
        "        downsample (nn.Sequential): Optional downsampling shortcut connection.\n",
        "\n",
        "    Methods:\n",
        "        forward(x):\n",
        "            Defines the forward pass of the Bottleneck block.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 in_channel=256, hidden_=64, out_channel=256,\n",
        "                 kernel_sizes=1, stride=1,\n",
        "                 downsample=True, change_kernel=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.downsamples = downsample  # Flag for applying downsampling\n",
        "\n",
        "        # First 1x1 convolution: reduces the number of channels (dimensionality reduction)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channel, out_channels=hidden_,\n",
        "            kernel_size=kernel_sizes, stride=stride, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(hidden_, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        # Second 3x3 convolution: applies spatial processing\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=hidden_, out_channels=hidden_,\n",
        "            kernel_size=3, padding=1, stride=stride, bias=False\n",
        "        )\n",
        "        if change_kernel:  # Modify stride for downsampling in the second convolution\n",
        "            self.conv2 = nn.Conv2d(\n",
        "                in_channels=hidden_, out_channels=hidden_,\n",
        "                kernel_size=3, padding=1, stride=2, bias=False\n",
        "            )\n",
        "        self.bn2 = nn.BatchNorm2d(hidden_, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        # Third 1x1 convolution: restores the number of channels (dimensionality restoration)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels=hidden_, out_channels=out_channel,\n",
        "            kernel_size=kernel_sizes, stride=stride, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        # ReLU activation: introduces non-linearity\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Downsampling shortcut if specified\n",
        "        if self.downsamples:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channel, out_channels=out_channel,\n",
        "                    kernel_size=kernel_sizes, stride=stride, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "            )\n",
        "            if change_kernel:  # Modify stride for downsampling in the shortcut path\n",
        "                self.downsample = nn.Sequential(\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channel, out_channels=out_channel,\n",
        "                        kernel_size=kernel_sizes, stride=2, bias=False\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(out_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the Bottleneck block.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, in_channel, height, width).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after applying the Bottleneck operations.\n",
        "        \"\"\"\n",
        "        skip_x = x  # Store the original input for the residual connection\n",
        "\n",
        "        # Apply the three convolutional layers with BatchNorm\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        # Add the residual (shortcut) connection\n",
        "        if self.downsamples:\n",
        "            x = self.downsample(skip_x) + x\n",
        "\n",
        "        x = self.relu(x)  # Apply ReLU activation to the final output\n",
        "        return x"
      ],
      "metadata": {
        "id": "j6Og-p5ij-M0"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet-50 architecture from scratch\n",
        "\n",
        "In this section, we implement the ResNet-50 architecture from scratch. ResNet-50 is a widely used deep convolutional neural network designed for image classification tasks. It is known for its ability to achieve high performance on complex datasets due to the use of residual connections that mitigate the vanishing gradient problem in deep networks.\n",
        "\n",
        "Our implementation follows these key steps:\n",
        "\n",
        "Initial Layers: The model begins with a convolutional layer, followed by batch normalization, ReLU activation, and max pooling, which reduce the input's spatial dimensions while capturing essential features.\n",
        "Residual Layers: The core of the model consists of four main stages (layer1 to layer4). Each stage is built using Bottleneck blocks, which include shortcut connections that directly add the input to the output of a stack of convolutional layers. The number of filters increases progressively across layers, allowing the model to learn hierarchical feature representations.\n",
        "Global Pooling and Classification: After the residual layers, the model applies adaptive average pooling to reduce the spatial dimensions to a fixed size. A fully connected layer maps the extracted features to class probabilities.\n",
        "This design reflects the structure of the original ResNet-50 architecture. By implementing it step by step, we not only replicate its functionality but also gain a deeper understanding of its inner workings. Finally, we prepare the model to load pretrained weights, which enhances its performance on various tasks without the need for training from scratch."
      ],
      "metadata": {
        "id": "m7BcJ9RnL6Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeT_copy(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of the ResNet-50 architecture from scratch.\n",
        "\n",
        "    This class builds the ResNet-50 model step by step using the following components:\n",
        "    - Initial convolutional layer with BatchNorm, ReLU, and max pooling.\n",
        "    - Four sequential layers (layer1 to layer4) comprising Bottleneck blocks,\n",
        "      with increasing channel dimensions as the network deepens.\n",
        "    - Adaptive average pooling to reduce the spatial dimensions to 1x1.\n",
        "    - Fully connected (linear) layer for classification.\n",
        "\n",
        "    Args:\n",
        "        None. Default settings are used to build ResNet-50.\n",
        "\n",
        "    Attributes:\n",
        "        conv1 (nn.Conv2d): Initial convolutional layer with 64 filters of size 7x7.\n",
        "        bn1 (nn.BatchNorm2d): Batch normalization layer for the initial convolution.\n",
        "        relu (nn.ReLU): ReLU activation function.\n",
        "        maxpool (nn.MaxPool2d): Max pooling layer to reduce spatial dimensions.\n",
        "        layer1-4 (nn.Sequential): Stacked Bottleneck blocks forming the ResNet layers.\n",
        "        avgpool (nn.AdaptiveAvgPool2d): Adaptive average pooling to produce a fixed-size feature map.\n",
        "        fc (nn.Linear): Fully connected layer for classification into 1000 classes.\n",
        "\n",
        "    Methods:\n",
        "        forward(x):\n",
        "            Defines the forward pass through the entire ResNet-50 model.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial convolutional layer: captures basic image features\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64,\n",
        "            kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu = nn.ReLU(inplace=True)  # Adds non-linearity\n",
        "        self.maxpool = nn.MaxPool2d(3, 2, 1, dilation=1, ceil_mode=False)\n",
        "\n",
        "        # First layer: 64 input channels, expanded to 256 in the bottleneck blocks\n",
        "        self.layer1 = nn.Sequential(\n",
        "            Bottleneck(64),  # First Bottleneck block with downsampling\n",
        "            *[Bottleneck(downsample=False) for i in range(2)]  # Two additional blocks\n",
        "        )\n",
        "\n",
        "        # Second layer: Expands from 256 to 512 channels\n",
        "        self.layer2 = nn.Sequential(\n",
        "            Bottleneck(256, 128, 512, change_kernel=True),  # First block with stride 2\n",
        "            *[Bottleneck(512, 128, 512, downsample=False) for i in range(3)]  # Additional blocks\n",
        "        )\n",
        "\n",
        "        # Third layer: Expands from 512 to 1024 channels\n",
        "        self.layer3 = nn.Sequential(\n",
        "            Bottleneck(512, 256, 1024, change_kernel=True),  # First block with stride 2\n",
        "            *[Bottleneck(1024, 256, 1024, downsample=False) for i in range(5)]  # Additional blocks\n",
        "        )\n",
        "\n",
        "        # Fourth layer: Expands from 1024 to 2048 channels\n",
        "        self.layer4 = nn.Sequential(\n",
        "            Bottleneck(1024, 512, 2048, change_kernel=True),  # First block with stride 2\n",
        "            *[Bottleneck(2048, 512, 2048, downsample=False) for i in range(2)]  # Additional blocks\n",
        "        )\n",
        "\n",
        "        # Adaptive average pooling: Reduces each feature map to 1x1\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layer: Maps the 2048 features to 1000 classes\n",
        "        self.fc = nn.Linear(2048, 1000, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the ResNet-50 model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, 3, height, width).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with shape (batch_size, 1000), representing class scores.\n",
        "        \"\"\"\n",
        "        # Initial convolutional block\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Pass through the ResNet layers\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        # Flatten and apply the fully connected layer\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "mfHk0HwFkqTA"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verification:\n",
        "\n",
        "To verify the functionality of the ResNet-50 implementation, we perform a simple forward pass using a test tensor. This tensor simulates an image batch with the following characteristics:\n",
        "\n",
        "Shape: (1, 3, 224, 224):\n",
        "Batch size = 1 (single image).\n",
        "Channels = 3 (RGB image).\n",
        "Height and Width = 224 pixels (standard input size for ResNet models).\n",
        "The goal of this test is to ensure that the network processes the input tensor correctly through all layers and outputs a tensor with the expected shape (1, 1000)—representing predictions for 1000 classes (as per ImageNet classification)."
      ],
      "metadata": {
        "id": "zumxfiq8Mi4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the ResNet-50 implementation with a dummy input tensor.\n",
        "test_tensor = torch.ones((1, 3, 224, 224))  # Create a tensor simulating a batch of RGB images.\n",
        "\n",
        "# Instantiate the ResNet-50 model and pass the test tensor through it.\n",
        "output = ResNeT_copy()(test_tensor)\n",
        "\n",
        "# Print the shape of the output tensor.\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBm_egrwwvTi",
        "outputId": "704d8869-050d-4428-80eb-53e0401ba046"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchinfo"
      ],
      "metadata": {
        "id": "Z7ff4Uob3Bbo"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the model\n",
        "from torchinfo import summary\n",
        "summary(model=ResNeT_copy(),input_size=(1,3,224,224),col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
        "        col_width=15,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuHVzHm_8_KD",
        "outputId": "f5054564-f118-49ec-d9da-7e1dc56b2e1c"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type (var_name))                  Input Shape     Output Shape    Param #         Trainable\n",
              "====================================================================================================\n",
              "ResNeT_copy (ResNeT_copy)                [1, 3, 224, 224] [1, 1000]       --              True\n",
              "├─Conv2d (conv1)                         [1, 3, 224, 224] [1, 64, 112, 112] 9,408           True\n",
              "├─BatchNorm2d (bn1)                      [1, 64, 112, 112] [1, 64, 112, 112] 128             True\n",
              "├─ReLU (relu)                            [1, 64, 112, 112] [1, 64, 112, 112] --              --\n",
              "├─MaxPool2d (maxpool)                    [1, 64, 112, 112] [1, 64, 56, 56] --              --\n",
              "├─Sequential (layer1)                    [1, 64, 56, 56] [1, 256, 56, 56] --              True\n",
              "│    └─Bottleneck (0)                    [1, 64, 56, 56] [1, 256, 56, 56] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56] [1, 64, 56, 56] 4,096           True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56] [1, 64, 56, 56] 128             True\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56] [1, 64, 56, 56] 36,864          True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56] [1, 64, 56, 56] 128             True\n",
              "│    │    └─Conv2d (conv3)               [1, 64, 56, 56] [1, 256, 56, 56] 16,384          True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56] [1, 256, 56, 56] 512             True\n",
              "│    │    └─Sequential (downsample)      [1, 64, 56, 56] [1, 256, 56, 56] 16,896          True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 56, 56] [1, 256, 56, 56] --              --\n",
              "│    └─Bottleneck (1)                    [1, 256, 56, 56] [1, 256, 56, 56] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 56, 56] [1, 64, 56, 56] 16,384          True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56] [1, 64, 56, 56] 128             True\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56] [1, 64, 56, 56] 36,864          True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56] [1, 64, 56, 56] 128             True\n",
              "│    │    └─Conv2d (conv3)               [1, 64, 56, 56] [1, 256, 56, 56] 16,384          True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56] [1, 256, 56, 56] 512             True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 56, 56] [1, 256, 56, 56] --              --\n",
              "│    └─Bottleneck (2)                    [1, 256, 56, 56] [1, 256, 56, 56] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 56, 56] [1, 64, 56, 56] 16,384          True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56] [1, 64, 56, 56] 128             True\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56] [1, 64, 56, 56] 36,864          True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56] [1, 64, 56, 56] 128             True\n",
              "│    │    └─Conv2d (conv3)               [1, 64, 56, 56] [1, 256, 56, 56] 16,384          True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56] [1, 256, 56, 56] 512             True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 56, 56] [1, 256, 56, 56] --              --\n",
              "├─Sequential (layer2)                    [1, 256, 56, 56] [1, 512, 28, 28] --              True\n",
              "│    └─Bottleneck (0)                    [1, 256, 56, 56] [1, 512, 28, 28] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 56, 56] [1, 128, 56, 56] 32,768          True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 56, 56] [1, 128, 56, 56] 256             True\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 56, 56] [1, 128, 28, 28] 147,456         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28] [1, 128, 28, 28] 256             True\n",
              "│    │    └─Conv2d (conv3)               [1, 128, 28, 28] [1, 512, 28, 28] 65,536          True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28] [1, 512, 28, 28] 1,024           True\n",
              "│    │    └─Sequential (downsample)      [1, 256, 56, 56] [1, 512, 28, 28] 132,096         True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 28, 28] [1, 512, 28, 28] --              --\n",
              "│    └─Bottleneck (1)                    [1, 512, 28, 28] [1, 512, 28, 28] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 512, 28, 28] [1, 128, 28, 28] 65,536          True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28] [1, 128, 28, 28] 256             True\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28] [1, 128, 28, 28] 147,456         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28] [1, 128, 28, 28] 256             True\n",
              "│    │    └─Conv2d (conv3)               [1, 128, 28, 28] [1, 512, 28, 28] 65,536          True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28] [1, 512, 28, 28] 1,024           True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 28, 28] [1, 512, 28, 28] --              --\n",
              "│    └─Bottleneck (2)                    [1, 512, 28, 28] [1, 512, 28, 28] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 512, 28, 28] [1, 128, 28, 28] 65,536          True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28] [1, 128, 28, 28] 256             True\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28] [1, 128, 28, 28] 147,456         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28] [1, 128, 28, 28] 256             True\n",
              "│    │    └─Conv2d (conv3)               [1, 128, 28, 28] [1, 512, 28, 28] 65,536          True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28] [1, 512, 28, 28] 1,024           True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 28, 28] [1, 512, 28, 28] --              --\n",
              "│    └─Bottleneck (3)                    [1, 512, 28, 28] [1, 512, 28, 28] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 512, 28, 28] [1, 128, 28, 28] 65,536          True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28] [1, 128, 28, 28] 256             True\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28] [1, 128, 28, 28] 147,456         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28] [1, 128, 28, 28] 256             True\n",
              "│    │    └─Conv2d (conv3)               [1, 128, 28, 28] [1, 512, 28, 28] 65,536          True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28] [1, 512, 28, 28] 1,024           True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 28, 28] [1, 512, 28, 28] --              --\n",
              "├─Sequential (layer3)                    [1, 512, 28, 28] [1, 1024, 14, 14] --              True\n",
              "│    └─Bottleneck (0)                    [1, 512, 28, 28] [1, 1024, 14, 14] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 512, 28, 28] [1, 256, 28, 28] 131,072         True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 28, 28] [1, 256, 28, 28] 512             True\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 28, 28] [1, 256, 14, 14] 589,824         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv3)               [1, 256, 14, 14] [1, 1024, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14] [1, 1024, 14, 14] 2,048           True\n",
              "│    │    └─Sequential (downsample)      [1, 512, 28, 28] [1, 1024, 14, 14] 526,336         True\n",
              "│    │    └─ReLU (relu)                  [1, 1024, 14, 14] [1, 1024, 14, 14] --              --\n",
              "│    └─Bottleneck (1)                    [1, 1024, 14, 14] [1, 1024, 14, 14] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14] [1, 256, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14] [1, 256, 14, 14] 589,824         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv3)               [1, 256, 14, 14] [1, 1024, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14] [1, 1024, 14, 14] 2,048           True\n",
              "│    │    └─ReLU (relu)                  [1, 1024, 14, 14] [1, 1024, 14, 14] --              --\n",
              "│    └─Bottleneck (2)                    [1, 1024, 14, 14] [1, 1024, 14, 14] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14] [1, 256, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14] [1, 256, 14, 14] 589,824         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv3)               [1, 256, 14, 14] [1, 1024, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14] [1, 1024, 14, 14] 2,048           True\n",
              "│    │    └─ReLU (relu)                  [1, 1024, 14, 14] [1, 1024, 14, 14] --              --\n",
              "│    └─Bottleneck (3)                    [1, 1024, 14, 14] [1, 1024, 14, 14] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14] [1, 256, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14] [1, 256, 14, 14] 589,824         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv3)               [1, 256, 14, 14] [1, 1024, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14] [1, 1024, 14, 14] 2,048           True\n",
              "│    │    └─ReLU (relu)                  [1, 1024, 14, 14] [1, 1024, 14, 14] --              --\n",
              "│    └─Bottleneck (4)                    [1, 1024, 14, 14] [1, 1024, 14, 14] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14] [1, 256, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14] [1, 256, 14, 14] 589,824         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv3)               [1, 256, 14, 14] [1, 1024, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14] [1, 1024, 14, 14] 2,048           True\n",
              "│    │    └─ReLU (relu)                  [1, 1024, 14, 14] [1, 1024, 14, 14] --              --\n",
              "│    └─Bottleneck (5)                    [1, 1024, 14, 14] [1, 1024, 14, 14] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14] [1, 256, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14] [1, 256, 14, 14] 589,824         True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14] [1, 256, 14, 14] 512             True\n",
              "│    │    └─Conv2d (conv3)               [1, 256, 14, 14] [1, 1024, 14, 14] 262,144         True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14] [1, 1024, 14, 14] 2,048           True\n",
              "│    │    └─ReLU (relu)                  [1, 1024, 14, 14] [1, 1024, 14, 14] --              --\n",
              "├─Sequential (layer4)                    [1, 1024, 14, 14] [1, 2048, 7, 7] --              True\n",
              "│    └─Bottleneck (0)                    [1, 1024, 14, 14] [1, 2048, 7, 7] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14] [1, 512, 14, 14] 524,288         True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 14, 14] [1, 512, 14, 14] 1,024           True\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 14, 14] [1, 512, 7, 7]  2,359,296       True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]  [1, 512, 7, 7]  1,024           True\n",
              "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]  [1, 2048, 7, 7] 1,048,576       True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7] [1, 2048, 7, 7] 4,096           True\n",
              "│    │    └─Sequential (downsample)      [1, 1024, 14, 14] [1, 2048, 7, 7] 2,101,248       True\n",
              "│    │    └─ReLU (relu)                  [1, 2048, 7, 7] [1, 2048, 7, 7] --              --\n",
              "│    └─Bottleneck (1)                    [1, 2048, 7, 7] [1, 2048, 7, 7] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 2048, 7, 7] [1, 512, 7, 7]  1,048,576       True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]  [1, 512, 7, 7]  1,024           True\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]  [1, 512, 7, 7]  2,359,296       True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]  [1, 512, 7, 7]  1,024           True\n",
              "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]  [1, 2048, 7, 7] 1,048,576       True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7] [1, 2048, 7, 7] 4,096           True\n",
              "│    │    └─ReLU (relu)                  [1, 2048, 7, 7] [1, 2048, 7, 7] --              --\n",
              "│    └─Bottleneck (2)                    [1, 2048, 7, 7] [1, 2048, 7, 7] --              True\n",
              "│    │    └─Conv2d (conv1)               [1, 2048, 7, 7] [1, 512, 7, 7]  1,048,576       True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]  [1, 512, 7, 7]  1,024           True\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]  [1, 512, 7, 7]  2,359,296       True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]  [1, 512, 7, 7]  1,024           True\n",
              "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]  [1, 2048, 7, 7] 1,048,576       True\n",
              "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7] [1, 2048, 7, 7] 4,096           True\n",
              "│    │    └─ReLU (relu)                  [1, 2048, 7, 7] [1, 2048, 7, 7] --              --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [1, 2048, 7, 7] [1, 2048, 1, 1] --              --\n",
              "├─Linear (fc)                            [1, 2048]       [1, 1000]       2,049,000       True\n",
              "====================================================================================================\n",
              "Total params: 25,557,032\n",
              "Trainable params: 25,557,032\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 4.09\n",
              "====================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 177.83\n",
              "Params size (MB): 102.23\n",
              "Estimated Total Size (MB): 280.66\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pretrained weights into our custom ResNet-50 model\n",
        "\n",
        "In this part, we load pretrained weights into our custom ResNet-50 model. Using pretrained weights allows the model to leverage knowledge learned from large datasets (like ImageNet) without requiring extensive training from scratch. This greatly improves performance for tasks such as image classification.\n",
        "\n",
        "Here’s what happens step by step:\n",
        "\n",
        "Retrieve Pretrained Weights: The pretrained weights for ResNet-50 are obtained using torchvision.models.ResNet50_Weights.DEFAULT.get_state_dict(). These weights represent the parameters learned by the model during training on ImageNet.\n",
        "Load Weights: We load these weights into our ResNeT_copy model using load_state_dict(). The strict=True argument ensures that the structure of our model matches exactly with the weight definitions, preventing any mismatches."
      ],
      "metadata": {
        "id": "TQZaadxNNBAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_weights = torchvision.models.ResNet50_Weights.DEFAULT.get_state_dict()\n",
        "pretrained_weights\n",
        "\n",
        "\n",
        "ResNeT_copy().load_state_dict(pretrained_weights , strict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxvVXi7zI1Gv",
        "outputId": "99936be7-a5dc-492a-cbd3-6dec477d3775"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITNJq7ZkJW4l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}